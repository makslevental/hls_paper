\documentclass[sigconf,techreport]{acmart}

\input{preamble.tex}

\newif\iffinal
\finalfalse


\iffinal
	\newcommand{\maxx}[1]{}
	\newcommand{\ryan}[1]{}
	\newcommand{\kyle}[1]{}
	\newcommand{\ian}[1]{}
	\newcommand{\arham}[1]{}
	\newcommand{\commnt}[2]{#2}
\else
	\newcommand{\maxx}[1]{{\textcolor{red}{ Max: #1 }}}
	\newcommand{\ryan}[1]{{\textcolor{magenta}{ Ryan: #1 }}}
	\newcommand{\kyle}[1]{{\textcolor{yellow}{ Kyle: #1 }}}
	\newcommand{\ian}[1]{{\textcolor{orange}{ Ian: #1 }}}
	\newcommand{\arham}[1]{{\textcolor{pink}{ Arham: #1 }}}
	\newcommand{\commnt}[2]{{{\color{green} \{#1\}} {\color{blue} #2}}}
\fi


\begin{document}

\title{A Framework for Counting Archived Frogs}

\author{Maksim Levental, Arham, Kaz, Ryan "the champ", Kyle, and Ian Foster}
\affiliation{%
	\institution{University of Chicago}
	\department{Department of Computer Science}
	\city{Chicago}
	\state{Illinois}
	\postcode{60637}
	\country{USA}
}
\email{{mlevental,..,foster}@uchicago.edu}

\renewcommand{\shortauthors}{Levental et al.}


\begin{abstract}
	In many experiment-driven scientific domains, such as high-energy physics and X-ray crystallography, high sample rates necessitate low latency near-sensor data processing.
	Thanks to a recent profusion in high-level frameworks, and example models, Deep Neural Network (DNN) models have been investigated for such use cases.
	Despite such investigations, few DNNs have been deployed in practice, owing to the inability of deployment targets (hardware accelerators) to meet hard latency and collocation constraints.
	Here we present a case-study of translating/deploying a particular X-ray crystallography DNN model to an alternative platform, namely Field Programmable Gate Arrays.
	We discuss some of the currently available workflows, toolchains, and their advantages and disadvantages.
	Further we discuss an application specific design methodology (specific to this model) to general purpose tools.
	Our approach achieves lower latency than any of the alternatives at the cost of generalizability, achieving 3Âµs/333KHz.
	Finally, we discuss extensions to our methodology that would enable generalization without any sacrifice in performance.
\end{abstract}


%    \begin{CCSXML}
%    <ccs2012>
%    <concept>
%    <concept_id>
%        10002951.10003227.10003392</concept_id>
%        <concept_desc>Information systems~Digital libraries and archives</concept_desc>
%        <concept_significance>500</concept_significance>
%        </concept>
%        <concept>
%        <concept_id>10002951.10003260</concept_id>
%        <concept_desc>Information systems~World Wide Web</concept_desc>
%        <concept_significance>500</concept_significance>
%        </concept>
%        </ccs2012>
%    \end{CCSXML}

\ccsdesc[500]{Information systems~Digital libraries and archives}
\ccsdesc[500]{Information systems~World Wide Web}

% Comment the above block out to hide CCS Concepts or update as per https://dl.acm.org/ccs/ccs.cfm


\keywords{Memento, Web Archiving, Frogs}


\maketitle

\section{Introduction}\label{sec:introduction}
\input{introduction.tex}

\section{Background}\label{sec:background}
\input{background.tex}

\section{Methodology}\label{sec:methodology}
\input{methodology.tex}

\section{Evaluation}\label{sec:evaluation}
\input{evaluation.tex}

\section{Acknowledgements}

% \todo


\bibliographystyle{ACM-Reference-Format}
\bibliography{ref}


\end{document}
