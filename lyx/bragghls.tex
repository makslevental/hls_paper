%% LyX 2.3.6.2 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[twocolumn,conference]{IEEEtran}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{verbatim}
\usepackage{textcomp}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[unicode=true,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=1,
 breaklinks=false,pdfborder={0 0 0},pdfborderstyle={},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{pdftitle={Your Title},
 pdfauthor={Your Name},
 pdfpagelayout=OneColumn, pdfnewwindow=true, pdfstartview=XYZ, plainpages=false}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
% for subfigures/subtables
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{hyperref}
\hypersetup{colorlinks=true}
\usepackage[dvipsnames]{xcolor}
\definecolor{lgray}{rgb}{0.95, 0.95, 0.95}

\@ifundefined{showcaptionsetup}{}{%
 \PassOptionsToPackage{caption=false}{subfig}}
\usepackage{subfig}
\makeatother

\usepackage{minted}
\renewcommand{\listingscaption}{Listing}

\begin{document}
\title{\texttt{BraggHLS}}
\author{\IEEEauthorblockN{Maksim~Levental}\IEEEauthorblockA{University of Chicago\\
Email: test@test.tes}\and \IEEEauthorblockN{Ryan~Chard}\IEEEauthorblockA{Ecole Superieure\\
Nantes, France\\
Email: second@second.fr}\and \IEEEauthorblockN{Kyle~Chard\\
and Ian~Foster}\IEEEauthorblockA{Star Academy\\
San Francisco, California 99999-9999\\
Telephone: (800) 555\textendash 5555\\
Fax: (888) 555\textendash 5555}}
\maketitle
\begin{abstract}
In many experiment-driven scientific domains, such as high-energy
physics, material science, and cosmology, very high data rate experiments
impose hard constraints on the corresponding data acquisition systems:
collected data must either be indiscriminately stored for post-processing
and analysis, thereby necessitating large storage capacity, or accurately
filtered in real-time, thereby necessitating low latency execution.
Deep neural networks, effective in many other filtering tasks, have
not been widely employed in such data acquisition systems, due to
design and deployment difficulties. This paper presents an open source,
lightweight, compiler framework \texttt{BraggHLS}, based on high-level
synthesis techniques, for translating high-level representations of
deep neural networks to low-level representations, suitable for deployment
to near-sensor devices such as field-programmable gate arrays. We
present a case study and evaluation of \texttt{BraggHLS} on a deep
neural network for Bragg peak detection in the context of high-energy
diffraction microscopy. We show \texttt{BraggHLS} is able to produce
an implementation with a throughput 4.7\textmu s/sample, which is
approximately a 5x improvement over the existing implementation.

\tableofcontents{}
\end{abstract}


\section{Introduction}

Very high data rates are observed and, consequently, large datasets
are generated across a broad range of experiments in scientific domains,
such as high-energy physics, material science, and cosmology. For
example, in high-energy physics, the LHCb detector, at the CERN Large
Hadron Collider, is tasked with observing the trajectories of particles
produced in proton-proton collisions at a rate of 40 million per second
(i.e., 40 MHz) \cite{pmlr-v42-glig14}. With a packet size of approximately
50kB (per collision), this implies a data rate of approximately 2TB/s.
Ultimately, in combination with other detectors, the LHC processes
approximately 100EB of data a year. In materials science, high-energy
diffraction microscopy (HEDM) techniques, which provide non-destructive
characterization of structure and its evolution in a broad class of
single-crystal and polycrystalline materials, can have collection
rates approaching 1 MHz \cite{Hammer_2021}, with a corresponding
packet size of 80kB. In cosmology, the Square Kilometre Array, a radio
telescope projected to be completed in 2024 and to be operational
by 2027 \cite{mcmullin2022square}, will sustain data rates in excess
of 10 TB/s \cite{grainge2017square}.

Naturally, for high data rate experiments, directly storing and distributing
such large quantities of data to the associated research communities
for further analysis is cost prohibitive. Thus, either compression
(in the case of storage and transmission) or outright filtering is
necessary, i.e., only a small fraction of the most ``interesting''
data is selected at time of collection, with the remainder being permanently
discarded. In this work we focus on the filtering approach. Note,
that the tradeoff made in employing filtering should be clear: reduced
storage at the expense of more stringent latency constraints (on the
filtering mechanisms). In addition, the risk of discarding meaningful
data introduces accuracy (of the filtering mechanisms) as a critical
new dimension of the data acquisition systems. Typically, these filtering
mechanisms consist either of physics based models \cite{LHCB-FIGURE-2020-018}
or machine learning models \cite{Gligorov_2013}; in either case maximally
efficient and effective use of the target hardware platform is tantamount
to accuracy. Irrespective of the type of technique employed, almost
universally, for the ultra-low latency use cases (e.g., sub-microsecond
latency constraints), the implementation is deployed to either field-programmable
gate arrays (FPGAs) or application-specific integrated circuits (ASICs)
\cite{Duarte_2018}. %
\begin{comment}
The reason for this is only FPGAs and ASICs are flexible enough to
satisfy the latency constraints for a wide range of techniques. Note,
in this work we focus exclusively on FPGAs.
\end{comment}

Deep neural networks (DNNs), a particular type of machine learning
model, have been shown to be effective in many scientific and commercial
domains due to their ``representational capacity'', i.e., they demonstrate
a capacity to (approximately) represent diverse sets of mappings \cite{alzubaidi2021review}.
DNNs ``learn'' to represent a mapping over the course of ``training'',
wherein they are iteratively evaluated on sample data while a ``learning
rule'' periodically updates the parameters (\emph{weights}) that
parameterize the DNN. In recent years they have been investigated
for near real-time scientific use cases \cite{liu2019deep,patton2018167,liu2022exploring}
but their use for the lowest latency use cases has been very limited
\cite{Duarte_2018}. The reasons for this are threefold: 
\begin{enumerate}
\item Graphics Processing Units (GPUs), the conventional hardware target
for DNNs, until very recently, have not been performant enough for
these very high data rate, very low latency, use cases (due to their
low clock speeds and low peripheral bandwidth \cite{aaij2020allen});
\item DNNs, by virtue of their depth, are resource intensive, in terms of
both memory (for the weights) and compute (floating point arithmetic),
thereby preventing their deployment to FPGAs, which, in particular,
have limited static RAM available;
\item DNNs are (typically) defined, trained, and distributed using high-level
frameworks (such as PyTorch \cite{paszke2017automatic}, TensorFlow
\cite{https://doi.org/10.48550/arxiv.1603.04467}, MXNet \cite{https://doi.org/10.48550/arxiv.1512.01274}),
which abstract all implementation details from the user, thereby making
portability of existing model architectures (to e.g., FPGA) nigh impossible.
\end{enumerate}
These three barriers demand of a solution that can simultaneously
translate a high-level representation of a DNN to a low-level representation,
suitable for deployment to FPGA, while optimizing resource usage and
minimizing latency. In general, the task of \emph{lowering} high-level
representations of programs to lower-level representations is the
domain of a compiler. Similarly, the task of \emph{synthesizing} a\emph{
register-transfer level} (RTL) \emph{design}, rendered in a \emph{hardware
description language} (HDL), from a program, is the domain of high-level
synthesis (HLS) \cite{7368920}. While several such HLS tools exist
\cite{10.1145/2514740,Zhang2008,ferrandi2021bambu} and despite, often,
bundling robust optimizing compilers, they struggle to effectively
perform the necessary optimizations in reasonable amounts of time
(see Section \ref{sec:Evaluation}).

Recently, deep learning compilers (such as TVM \cite{chen2018tvm},
MLIR \cite{https://doi.org/10.48550/arxiv.2002.11054}, and Glow \cite{https://doi.org/10.48550/arxiv.1805.00907})
have demonstrated the ability to dramatically reduce inference latencies
\cite{https://doi.org/10.48550/arxiv.1809.02697}, training times
\cite{9664259}, and memory usage \cite{https://doi.org/10.48550/arxiv.1604.06174}
of DNNs. These compilers function by extracting intermediate-level
representations (IRs) of the DNNs, from the representations produced
by the frameworks, and performing various optimizations on those IRs
(such as kernel fusion \cite{10.1145/2858788.2688521}, vectorization
\cite{maleki2011evaluation}, and memory planning \cite{https://doi.org/10.48550/arxiv.1604.06174}).
The highly optimized IR is then used to generate code for various
target hardware platforms. Given the successes of these compilers,
it's natural to wonder whether they can adapted to the task of sufficiently
optimizing a DNN such that it might be synthesized to RTL, for deployment
to FPGA.

In this paper, we present \texttt{BraggHLS}, an open source, lightweight,
compiler and HLS framework which can lower DNNs defined as PyTorch
models to FPGA implementations. \texttt{BraggHLS} uses a combination
of compiler and HLS techniques to compile the entire DNN into a \emph{statically
scheduled} circuit, thereby eliminating all synchronization overheads
and achieving ultra-low latency. \texttt{BraggHLS} is general and
supports a wide range of DNN layer types, and thus a wide range of
DNNs, but particularly focus on a DNN designed for identifying Bragg
diffraction peaks. In summary our specific contributions include:
\begin{enumerate}
\item We discuss the challenges faced by a compiler and HLS tool in attempting
to lower DNNs to ultra-low latency designs, including runtime costs
incurred during design space exploration, challenges meeting resource
and timing constraints during synthesis, placement, and routing;
\item We describe and implement a compiler framework, \texttt{BraggHLS},
which can effectively transform unoptimized, hardware-agnostic PyTorch
models into ultra-low latency RTL designs suitable for deployment
to Xilinx FPGAs. \texttt{BraggHLS} is thoroughly tested, open source,
and available at \href{https://github.com/makslevental/bragghls/}{https://github.com/makslevental/bragghls/};
\item We show that designs generated by \texttt{BraggHLS} achieve lower
latency than Xilinx's state-of-the-art commercial HLS tool (Vitis
HLS) for a variety of DNN layer types. In particular we show that
\texttt{BraggHLS} can produce synthesizable designs that meet placement,
routing, and timing constraints, where Vitis HLS cannot.
\end{enumerate}
The rest of this paper is organized as follows: Section \ref{sec:Background}
reviews key concepts from compilers, high-level synthesis, and FPGA
design flows. Section \ref{sec:BraggHLS-compiler-and} describes the
\texttt{BraggHLS} compiler and HLS framework in detail. Section \ref{sec:Evaluation}
evaluates \texttt{BraggHLS}\textquoteright s performance, scalability,
and competitiveness with designs generated by Vitis HLS. Section \ref{sec:BraggNN-case-study}
describes our case study, \texttt{BraggHLS} applied to \texttt{BraggNN},
a Bragg peak detection DNN with a target latency of 1\textmu s/sample.
Finally, Section \ref{sec:Conclusion} concludes with a summary, and
related and future work.

\section{Background\label{sec:Background}}

\subsection{Compilers: the path from high to low}

The path from a high-level, abstract, representations of a DNN to
a register-transfer level representation can be neatly formulated
as a series of progressive lowerings between adjacent levels of abstraction.
Each level of abstraction is rendered as a programming language, IR,
or HDL, and thus we descibe each lowering in terms the representations
and tools \texttt{BraggHLS} employs:
\begin{enumerate}
\item An imperative, \emph{define-by-run,} Python representation, in PyTorch;
\item High-level data-flow graph representation, in TorchScript;
\item Low-level data and control flow graph representation, in MLIR.
\end{enumerate}
%

\subsubsection{PyTorch and TorchScript}

Typically DNN models are represented in terms of high-level frameworks,
themselves implemented within general purpose programming languages.
Such frameworks are widely used because of their ease of use and large
library of example implementations of various DNN model architectures.
\texttt{BraggHLS} is implemented using PyTorch, thus we focus on relevant
aspects of PyTorch. DNNs developed within PyTorch are \emph{defined-by-run}:
the author imperatively describes the DNN in terms of high-level operations,
using python, which when executed materializes the high-level data-flow
graph (DFG) corresponding to the DNN (e.g., for the purposes of reverse-mode
automatic differentiation). From the perspective of the user, define-by-run
enables fast iteration at development time, possibly at the cost of
some runtime performance. 

From the perspective of compilation, define-by-run precludes efficient
extraction of the high-level DFG; since the DFG is materialized only
at runtime, it cannot be inferred from the textual representation
(i.e., the python source) of the DNN. Furthermore, apriori, the runtime-materialized
DFG is only partially materialized\footnote{``...instead, every intermediate result records only the subset of
the computation graph that was relevant to their computation.'' \cite{paszke2017automatic}}, and only as an in-memory data structure. Thus, framework support
is necessary. Indeed, PyTorch supports a Single Static Assignment
(SSA) IR, called TorchScript (TS) IR and accompanying tracing mechanism
(the TS JIT) to produce TS IR from conventionally defined PyTorch
models. Lowering from PyTorch to TS IR enables various useful analyses
and transformations on a DNN at the level of the high-level DFG (such
as kernel fusion \cite{10.1145/2858788.2688521}) but targeting FPGAs
requires a broader collection of transformations. To this end, we
turn to a recent addition to the compiler ecosystem.

\subsubsection{MLIR}

Multi-level Intermediate Representation \cite{https://doi.org/10.48550/arxiv.2002.11054}
presents a new approach to building reusable and extensible compiler
infrastructure. MLIR is composed of a set of \emph{dialect} IRs, subsets
of which are mutually compatible, either outright or by way of translation/legalization.
The various dialects aim to capture and formalize the semantics of
compute intensive programs at varying levels of abstraction, as well
as namespace related sets of IR transformations. The entrypoint into
this compiler framework, from PyTorch, is the \texttt{torch} dialect
\cite{torch-mlir}, a high-fidelity mapping from TS IR to MLIR native
IR, which, in addition to performing the translation to MLIR, fully
refines all shapes of intermediate tensors in the DNN (i.e., computes
concrete values for all dimensions of each tensor); this is necessary
for downstream optimizations and eliminating inconsistencies in the
DNN \cite{https://doi.org/10.48550/arxiv.2203.08402}.

While the \texttt{torch} dialect is necessary for lowering to MLIR
and shape refinement, it is a representation of a DNN at the same
level of abstraction as TS IR: it does not capture the precise data
flow and control flow necessary for novel implementations of DNN operations
(e.g., for FPGA). Fortunately, MLIR supports lower-level dialects,
such as the \texttt{affine} and \texttt{scf} (structured control flow)
dialects. The \texttt{scf} dialect is a straightforward formalization
of control flow primitives, such as conditionals and loops. The \texttt{affine}
dialect, on the otherhand, provides a formalization of semantics that
lend themselves to polyhedral compilation techniques \cite{polyhedral-mlir},
i.e., techniques that enable loop dependence analysis and loop transformations.
Such loop transformations, particularly loop unrolling, are crucial
for achieving lowest possible latencies \cite{yehpca2022scalehls}.

\subsection{High-level synthesis and FPGA design}

\subsubsection{High-level synthesis\label{subsec:High-level-synthesis}}

High-level synthesis tools produce RTL descriptions of digital designs
from high-level representations, such as C or C++ \cite{10.1145/2514740,ferrandi2021bambu}.
In particular, Xilinx's Vitis HLS, based on the Autopilot project
\cite{Zhang2008}, is a state-of-the-art HLS tool. Given a high-level,
procedural, representation, HLS proceeds in three steps, in order
to produce a corresponding RTL design:
\begin{enumerate}
\item HLS schedules operations (such as \texttt{mulf}, \texttt{addf}, \texttt{load},
\texttt{store}) in order to determine which operations should occur
during each clock-cycle. Such a schedule depends on three characteristics
of the high-level representation:
\begin{enumerate}
\item The topological ordering of the DFG/CFG of the procedural representation
(i.e., the dependencies of operations on results of other operations
and resources);
\item The completion time for each operation;
\item The user's desired clock rate/frequency;
\end{enumerate}
\item HLS associates operations to particular RTL instantiations (called
\emph{binding}) for those operations; for example whether to associate
an add operation followed by a multiply operation to two separate
instances, or whether to associate them both with a single instance
(e.g., configured to perform a fused-multiply-add);
\item HLS builds a finite-state machine (FSM) that implements the schedule
of operations as control logic, i.e., logic that initiates operations
and routes signals between them during the appropriate FSM stages.
\end{enumerate}
In addition to fulfilling these three fundamental tasks, high-level
synthesis aims to optimize the program, during synthesis. In particular,
they try to maximize concurrency and parallelism (number of concurrent
operations scheduled during a clock-cycle) in order maximize the throughput
and minimize the latency of the final implementation. 

Maximizing parallelism entails rigorous data-flow analysis in order
to identify data dependencies that would lead to data hazards in synthesized
designs. This data-flow analysis exhibits extremely high runtime as
lower latency designs are pursued. This can be understood in terms
of loop-nest representations of DNN operations; for example consider
a convolution as in listing \ref{lis:Single-filter-convolution}.
\begin{listing}
\begin{minted}[fontsize={\footnotesize},escapeinside={||},mathescape=true]{python}
def conv2d(
  input: array(|$b$|, |$c_{in}$|, |$h$|, |$w$|),
  output: array(|$b$|, |$c_{out}$|, |$h$|, |$w$|),
  weight: array(|$c_{out}$|, |$c_{in}$|, |$k$|, |$k$|)
):
  for iv1 in range(0, |$b$|):
    for iv2 in range(0, |$c_{out}$|):
      for iv3 in range(0, |$h$|):
        for iv4 in range(0, |$w$|):
          for iv5 in range(0, |$c_{in}$|):
            for iv6 in range(0, |$k$|):
              for iv7 in range(0, |$k$|):
                _3 = iv3 + iv6
                _4 = iv4 + iv7
                _5 = input[iv1, iv5, _3, _4]
                _6 = weight[iv2, iv5, iv6, iv7]
                _7 = output[iv1, iv2, iv3, iv4]
                _8 = _5 * _6
                _9 = _7 + _8
                output[iv1, iv2, iv3, iv4] = _9
\end{minted}
\caption{Padding $\left\lfloor k/2\right\rfloor $, stride 1, $c_{out}$ filter
convolution with $k\times k$ kernel applied to ($\ensuremath{b},\ensuremath{c_{in}},\ensuremath{h},\ensuremath{w}$)-dimensional\texttt{
input} tensor, where $b$ is the batch size, $c_{in}$ is the number
of channels, and ($h,w$) are the height and width, respectively.\label{lis:Single-filter-convolution}}
\end{listing}
 A schedule for the arithmetic operations for this loop nest can be
computed by first unrolling all the loops up to some ``trip-count''
and then computing the topological sort of the operations (known as
\emph{list scheduling}). The degree to which the loops are unrolled
determines how many arithmetic operations can be scheduled in parallel.
The issue is that the stores and loads on the \texttt{output} array
prevent reconstruction of explicit relationships between the inputs
and outputs of the arithmetic operations across loop iterations. The
standard resolution is to perform \emph{store-load forwarding}: pairs
of store and load operations to/from the same memory address are eliminated,
with the operand of the store forwarded to the uses of the load (see
listing \ref{lis:Single-filter-convolution-1}).
\begin{listing}
\begin{minted}[numbers=left,fontsize={\footnotesize},escapeinside={||},mathescape=true,highlightlines={19,25}]{python}
def conv2d(
  input: array(|$b$|, |$c_{in}$|, |$h$|, |$w$|),
  output: array(|$b$|, |$c_{out}$|, |$h$|, |$w$|),
  weight: array(|$c_{out}$|, |$c_{in}$|, |$k$|, |$k$|)
):
  for iv1 in range(0, |$b$|):
    for iv2 in range(0, |$c_{out}$|):
      for iv3 in range(0, |$h$|):
        for iv4 in range(0, |$w$|):
	  ...
	  # e.g., iv5, iv6, iv7 = 2, 3, ${\setlength{\fboxsep}{1pt}\colorbox{Salmon}{\texttt{4}}}$
	  _31 = iv3 + iv6 
	  _41 = iv4 + iv7 
	  _51 = input[iv1, iv5, _31, _41] 
	  _61 = weight[iv2, iv5, iv6, iv7] 
	  _71 = output[iv1, iv2, iv3, iv4] 
	  _81 = _51 * _61 
	  |${\setlength{ \fboxsep}{1pt} \colorbox{green}{ \texttt{\_91}}}$| = _71 + _81 
	  output[iv1, iv2, iv3, iv4] = _91 
	  # iv5, iv6, iv7 = 2, 3, ${\setlength{\fboxsep}{1pt}\colorbox{Salmon}{\texttt{5}}}$
	  _32 = iv3 + iv6 
	  _42 = iv4 + iv7 
	  _52 = input[iv1, iv5, _32, _42] 
	  _62 = weight[iv2, iv5, iv6, iv7] 
	  |${\setlength{\fboxsep}{1pt}\colorbox{yellow}{\texttt{\_72}}}$| = output[iv1, iv2, iv3, iv4] 
	  _82 = _52 * _62 
	  _92 = |${\setlength{\fboxsep}{1pt}\colorbox{yellow}{\texttt{\_72}}}$| + _82 
	  output[iv1, iv2, iv3, iv4] = _92
	  ...
\end{minted}
\caption{Store-load forwarding across successive iterations (e.g.,\texttt{
iv7} $={\setlength{\fboxsep}{1pt}\colorbox{Salmon}{\texttt{4}}}, {\setlength{\fboxsep}{1pt}\colorbox{Salmon}{\texttt{5}}}$)
of the inner loop in listing \ref{lis:Single-filter-convolution},
after unrolling. The forwarding opportunity is from the store on line
19 to the load on line 25; both can be eliminated and ${\setlength{\fboxsep}{1pt}\colorbox{green}{\texttt{\_91}}}$
can replace uses of ${\setlength{\fboxsep}{1pt}\colorbox{yellow}{\texttt{\_72}}}$,
such as in the computation of \texttt{\_92} (and potentially many
others).\label{lis:Single-filter-convolution-1}}
\end{listing}
 In order for this transformation to be correct (preserve program
semantics), for each pair of candidate store and load operations,
it must be verified that there are no intervening memory operations.
Note, the number of such checks scales polynomially in the parameters
of the convolution since the loop nest unrolls into $b\times c_{out}\times h\times w\times c_{in}\times k^{2}$
store-load pairs. Note also, while in the case of listing \ref{lis:Single-filter-convolution}
the verification is straightforward, in general it might involve solving
a small constraint satisfaction program \cite{rajopadhye2002dependence}.

Finally, note, though greedy solutions to the scheduling problem solved
by HLS are possible, in principle scheduling is an integer linear
programming problem (ILP), instances of which are NP-hard. In summary,
HLS tools solve computationally intensive problems in order to produce
a RTL description of a high-level representation of a DNN. These phases
of the HLS process incur ``development time'' costs (i.e., runtime
of the tools) and impose practical limitations on the amount of design
space exploration (for the purpose of achieving latency goals) which
can be performed. \texttt{BraggHLS }addresses these issues by enabling
the user to employ heuristics (during both the parallelization and
scheduling phases) which, while not guaranteed to be correct, can
be \emph{behaviourally verified} (see section \ref{subsec:Symbolic-execution-for}).

\subsection{FPGA design}

At the register-transfer level of abstraction, there remain two more
steps prior to being able to actually deploy to an FPGA; one of them
being a final lowering, so called logic synthesis, and the other being
place and route (P\&R). Logic synthesis is the process of mapping
RTL to actual hardware primitives on the FPGA (so-called \emph{technology
mapping}), such as lookup tables (LUTs), block RAMs (BRAMs), flip-flops
(FFs), and digital signal processors (DSPs). Logic synthesis produces
a network list (\emph{netlist}) describing the logical connectivity
of various parts of the design. Logic synthesis effectively determines
the implementation of floating point operations in terms of DSPs;
depending on user parameters and other design features, DSP resource
consumption for floating point multiplication and addition can differ
greatly. The number of LUTs and DSPs that a high-level representation
of a DNN corresponds to is relevant to both the performance and feasibility
of that DNN when deployed to FPGA.

After the netlist has been produced, the entire design undergoes P\&R.
The goal of P\&R is to determine which configurable logic block within
an FPGA should implement each of the units of logic required by the
digital design. P\&R algorithms need to minimize distances between
related units of functionality (in order to minimize wire delay),
balance wire density across the entire fabric of the FPGA (in order
to reduce route congestion), and maximize the clock speed of the design
(a function of both wire delay, logic complexity, and route congestion).
The final, routed design, can then be deployed to the FPGA by producing
a proprietary \emph{bitstream}, which is written to the FPGA.

\section{\texttt{BraggHLS} compiler and HLS framework\label{sec:BraggHLS-compiler-and}}

\texttt{BraggHLS} is a customizable HLS framework which employs MLIR
for extracting loop-nest representations of DNNs implemented as PyTorch
models. Critically, and distinctly, it handles the DNN transformations
as well as scheduling, binding, and FSM extraction; there is no dependence
on any commercial HLS tools. Figure \ref{fig:BraggHLS-framework-overview.}
shows the architecture of \texttt{BraggHLS} 
\begin{figure}[tbh]
\centering{}\includegraphics[width=1\columnwidth]{../figures/BraggHLS}\caption{\texttt{BraggHLS} framework overview (placeholder).\label{fig:BraggHLS-framework-overview.}}
\end{figure}
. We discuss the most significant aspects of the architecture in the
following.

\subsection{Abstract interpretation for efficient transformations\label{subsec:Symbolic-execution-for}}

First, DNNs are lowered from PyTorch to MLIR through TorchScript and
the \texttt{torch} dialect. They are then further lowered from the
\texttt{torch} dialect to the \texttt{scf} dialect (through the \texttt{linalg}
dialect) in such a way that the inherent parallelism of each high-level
operation is preserved (for example, see listing \ref{lis:Single-filter-convolution-2}).
\begin{listing}
\begin{minted}[fontsize={\footnotesize},escapeinside={||},mathescape=true]{mupad}
@conv2d(
    %input: memref<|$b \times c_{in} \times h \times w$|>,
    %weight: memref<|$b \times c_{out} \times h \times w$|>,
    %output: memref<|$c_{out} \times c_{in} \times k \times k$|>
) {
  scf.parallel (%iv1, %iv2, %iv3, %iv4) =
               (%c0, %c0, %c0, %c0) to
               (|$b$|, |$c_{out}$|, |$h$|, |$w$|) step
               (%c1, %c1, %c1, %c1) {
    scf.for %iv5 = %c0 to |$c_{in}$| step %c1 {
      scf.for %iv6 = %c0 to |$k$| step %c1 {
        scf.for %iv7 = %c0 to |$k$| step %c1 {
          %3 = arith.addi %iv3, %iv6
          %4 = arith.addi %iv4, %iv7
          %5 = memref.load %input[%iv1, %iv5, %iv3, %3, %4]
          %6 = memref.load %weight[%iv2, %iv5, %iv6, %iv7]
          %7 = memref.load %output[%iv1, %iv2, %iv3, %iv4]
          %8 = arith.mulf %5, %6
          %9 = arith.addf %7, %8
          memref.store %9, %output[%iv1, %iv2, %iv3, %iv4]
        }
      }
    }
  }
  return %2
}
\end{minted}
\caption{Parallel loop representation of the convolution in listing \ref{lis:Single-filter-convolution}.\label{lis:Single-filter-convolution-2}}
\end{listing}
The value of making the parallelism explicit is that we can readily
partition a DNN across a known set of hardware resources; since for
each value of (\texttt{\%iv1},\texttt{ \%iv2},\texttt{ \%iv3},\texttt{
\%iv4}) the body of the \texttt{scf.parallel} is independent of all
others we can bind all the respective operations to unique hardware
resources (DSPs, LUTs, and FFs). Thus, we can infer peak resource
usage by computing the maximum cardinality of the cartesian product
of the iteration spaces of the parallel iteration variables over all
such parallel loops. For example, the convolution in listing \ref{lis:Single-filter-convolution-2}
would bind to 
\begin{multline*}
K=\left|\left\{ \texttt{\%iv1}=\texttt{\%c0}+\texttt{\%c1}\times\mathbb{N}\,\wedge\,\texttt{\%iv1}<b\right\} \right|\times\\
\left|\left\{ \texttt{\%iv2}=\texttt{\%c0}+\texttt{\%c1}\times\mathbb{N}\,\wedge\,\texttt{\%iv2}<c_{out}\right\} \right|\times\\
\left|\left\{ \texttt{\%iv3}=\texttt{\%c0}+\texttt{\%c1}\times\mathbb{N}\,\wedge\,\texttt{\%iv3}<h\right\} \right|\times\\
\left|\left\{ \texttt{\%iv4}=\texttt{\%c0}+\texttt{\%c1}\times\mathbb{N}\,\wedge\,\texttt{\%iv4}<w\right\} \right|
\end{multline*}
collections of resources (such as $2K$ DSPs\footnote{One per floating point operation.}),
where $\texttt{\%c1}\times\mathbb{N}$ represents all multiples of
$\texttt{\%c1}$.

In addition to enabling us to perform binding, as discussed in section
\ref{subsec:High-level-synthesis}, a loop-nest representation enables
us to effectively perform data-flow analysis and schedule the encompassed
arithmetic operations, given that we can first unroll the loops. As
also discussed in section \ref{subsec:High-level-synthesis}, the
formally correct approach to unrolling a loop nest is prohibitively
expensive in terms of runtime. Indeed, for \texttt{BraggNN}, with
respect to producing a RTL representation achieving latency within
1000$\times$ of the target latency (i.e., $<$1 ms), performing this
unrolling in a reasonable amount of time (e.g., $<$12 hours) was
extremely challenging. 

To overcome this, the approach that \texttt{BraggHLS} takes is to
implement an \emph{abstract interpreter} for these loop-nest representations.
The \texttt{BraggHLS} interpreter unrolls loops by executing under
a redefined set semantics (hence abstract) them while enforcing SSA.
That is to say, for a loop whose body has repeated assignments to
the same value (ostensibly violating SSA), we execute the loop and
instantiate unique identifiers for the result of each operation. The
interpreter then evaluates functions of iteration variables, such
as \mintinline{mupad}!%3 = arith.addi %iv3, %iv6!. This enables us
to determine array index operands of all stores and loads, such as
\mintinline{mupad}!memref.load %input[%iv1, %iv5, %iv3, %3, %4]!.
Note, we do not evaluate values corresponding to floating point arithmetic,
as they represent true evaluation of the DNN; our interpreter represents
the operands of such operations as symbols and merely records the
arithmetic operations performed on them. This enables us to both unroll
the loop and track data-flow through arithmetic operations (see section
\ref{lis:Single-filter-convolution-1}). Finally, the interpreter
reinterprets \texttt{memref}s as \emph{geometric symbol tables} (i.e.,
symbol tables indexed by array indices rather than identifiers/names)
and stores and loads as assignments/reads to/from those symbol tables.
Such semantics, in combination with fully evaluated array indices,
enables \texttt{BraggHLS} to simultaneously track the flow of data
(through arithmetic operations and \texttt{memref}s), effectively
performing store-load forwarding.

\section{Evaluation\label{sec:Evaluation}}

asdasd
\begin{figure*}[tbh]
\begin{centering}
\subfloat[\texttt{addmm}]{\centering{}\includegraphics[width=1\columnwidth]{../data/addmm}\label{2dlattice-1-1-2}}\subfloat[\texttt{braggnn}]{\centering{}\includegraphics[width=1\columnwidth]{../data/braggnn}\label{2dlattice-1-2-2}}
\par\end{centering}
\medskip{}

\centering{}\label{2dlattice-1-3}\subfloat[\texttt{conv}]{\centering{}\includegraphics[width=1\columnwidth]{../data/conv}\label{2dlattice-1-1-1-1}}\subfloat[\texttt{matmul}]{\centering{}\includegraphics[width=1\columnwidth]{../data/matmul}\label{2dlattice-1-2-1-1}}\caption{Resource usage and latency vs. unroll factor of various DNN modules.}
\end{figure*}
\begin{figure*}[tbh]
\centering{}\includegraphics[width=1\columnwidth]{../data/elapsed_time}\caption{Runtime of Vitis HLS vs. unroll factor.}
\end{figure*}


\section{\texttt{BraggNN} case study\label{sec:BraggNN-case-study}}

\section{Conclusion\label{sec:Conclusion}}

\bibliographystyle{IEEEtran}
\bibliography{ref}

\end{document}
