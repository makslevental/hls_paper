#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass IEEEtran
\begin_preamble
% for subfigures/subtables
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{hyperref}
\hypersetup{colorlinks=true}
\end_preamble
\options conference
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package none
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures false
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command bibtex
\index_command default
\float_placement tbh
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_title "Your Title"
\pdf_author "Your Name"
\pdf_bookmarks true
\pdf_bookmarksnumbered true
\pdf_bookmarksopen true
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle false
\pdf_quoted_options "pdfpagelayout=OneColumn, pdfnewwindow=true, pdfstartview=XYZ, plainpages=false"
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\family typewriter
BraggHLS
\end_layout

\begin_layout Author
\begin_inset Flex Author Name
status open

\begin_layout Plain Layout
Maksim
\begin_inset space ~
\end_inset

Levental
\end_layout

\end_inset


\begin_inset Flex Author Affiliation
status open

\begin_layout Plain Layout
University of Chicago
\begin_inset Newline newline
\end_inset

Email: test@test.tes
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
and 
\end_layout

\end_inset


\begin_inset Flex Author Name
status open

\begin_layout Plain Layout
Ryan
\begin_inset space ~
\end_inset

Chard
\end_layout

\end_inset


\begin_inset Flex Author Affiliation
status open

\begin_layout Plain Layout
Ecole Superieure
\begin_inset Newline newline
\end_inset

Nantes, France
\begin_inset Newline newline
\end_inset

Email: second@second.fr
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
and 
\end_layout

\end_inset


\begin_inset Flex Author Name
status open

\begin_layout Plain Layout
Kyle
\begin_inset space ~
\end_inset

Chard
\begin_inset Newline newline
\end_inset

and Ian
\begin_inset space ~
\end_inset

Foster
\end_layout

\end_inset


\begin_inset Flex Author Affiliation
status collapsed

\begin_layout Plain Layout
Star Academy
\begin_inset Newline newline
\end_inset

San Francisco, California 99999-9999
\begin_inset Newline newline
\end_inset

Telephone: (800) 555–5555
\begin_inset Newline newline
\end_inset

Fax: (888) 555–5555
\end_layout

\end_inset


\end_layout

\begin_layout Abstract
In many experiment-driven scientific domains, such as high-energy physics,
 material science, and cosmology, very high data rate experiments impose
 hard constraints on the corresponding data acquisition systems: collected
 data must either be indiscriminately stored for post-processing and analysis,
 thereby necessitating large storage capacity, or accurately filtered in
 real-time, thereby necessitating low latency execution.
 Deep neural networks, effective in many other filtering tasks, have not
 been widely employed in such data acquisition systems, due to design and
 deployment difficulties.
 This paper presents an open source, lightweight, compiler framework 
\family typewriter
BraggHLS
\family default
, based on high-level synthesis techniques, for translating high-level represent
ations of deep neural networks to low-level representations, suitable for
 deployment to near-sensor devices such as field-programmable gate arrays.
 We present a case study and evaluation of 
\family typewriter
BraggHLS
\family default
 on a deep neural network for Bragg peak detection in the context of high-energy
 diffraction microscopy.
 We show 
\family typewriter
BraggHLS
\family default
 is able to produce an implementation with a throughput 4.7µs/sample, which
 is approximately a 5x improvement over the existing implementation.
\end_layout

\begin_layout Abstract
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Very high data rates are observed and, consequently, large datasets are
 generated across a broad range of experiments in scientific domains, such
 as high-energy physics, material science, and cosmology.
 For example, in high-energy physics, the LHCb detector, at the CERN Large
 Hadron Collider, is tasked with observing the trajectories of particles
 produced in proton-proton collisions at a rate of 40 million per second
 (i.e., 40 MHz) 
\begin_inset CommandInset citation
LatexCommand cite
key "pmlr-v42-glig14"
literal "false"

\end_inset

.
 With a packet size of approximately 50kB (per collision), this implies
 a data rate of approximately 2TB/s.
 Ultimately, in combination with other detectors, the LHC processes approximatel
y 100EB of data a year.
 In materials science, high-energy diffraction microscopy (HEDM) techniques,
 which provide non-destructive characterization of structure and its evolution
 in a broad class of single-crystal and polycrystalline materials, can have
 collection rates approaching 1 MHz 
\begin_inset CommandInset citation
LatexCommand cite
key "Hammer_2021"
literal "false"

\end_inset

, with a corresponding packet size of 80kB.
 In cosmology, the Square Kilometre Array, a radio telescope projected to
 be completed in 2024 and to be operational by 2027 
\begin_inset CommandInset citation
LatexCommand cite
key "mcmullin2022square"
literal "false"

\end_inset

, will sustain data rates in excess of 10 TB/s 
\begin_inset CommandInset citation
LatexCommand cite
key "grainge2017square"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Naturally, for high data rate experiments, directly storing and distributing
 such large quantities of data to the associated research communities for
 further analysis is cost prohibitive.
 Thus, either compression (in the case of storage and transmission) or outright
 filtering is necessary, i.e., only a small fraction of the most 
\begin_inset Quotes eld
\end_inset

interesting
\begin_inset Quotes erd
\end_inset

 data is selected at time of collection, with the remainder being permanently
 discarded.
 In this work we focus on the filtering approach.
 Note, that the tradeoff made in employing filtering should be clear: reduced
 storage at the expense of more stringent latency constraints (on the filtering
 mechanisms).
 In addition, the risk of discarding meaningful data introduces accuracy
 (of the filtering mechanisms) as a critical new dimension of the data acquisiti
on systems.
 Typically, these filtering mechanisms consist either of physics based models
 
\begin_inset CommandInset citation
LatexCommand cite
key "LHCB-FIGURE-2020-018"
literal "false"

\end_inset

 or machine learning models 
\begin_inset CommandInset citation
LatexCommand cite
key "Gligorov_2013"
literal "false"

\end_inset

; in either case maximally efficient and effective use of the target hardware
 platform is tantamount to accuracy.
 Irrespective of the type of technique employed, almost universally, for
 the ultra-low latency use cases (e.g., sub-microsecond latency constraints),
 the implementation is deployed to either field-programmable gate arrays
 (FPGAs) or application-specific integrated circuits (ASICs) 
\begin_inset CommandInset citation
LatexCommand cite
key "Duarte_2018"
literal "false"

\end_inset

.
 
\begin_inset Note Comment
status collapsed

\begin_layout Plain Layout
The reason for this is only FPGAs and ASICs are flexible enough to satisfy
 the latency constraints for a wide range of techniques.
 Note, in this work we focus exclusively on FPGAs.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Deep neural networks (DNNs), a particular type of machine learning model,
 have been shown to be effective in many scientific and commercial domains
 due to their 
\begin_inset Quotes eld
\end_inset

representational capacity
\begin_inset Quotes erd
\end_inset

, i.e., they demonstrate a capacity to (approximately) represent diverse sets
 of mappings 
\begin_inset CommandInset citation
LatexCommand cite
key "alzubaidi2021review"
literal "false"

\end_inset

.
 DNNs 
\begin_inset Quotes eld
\end_inset

learn
\begin_inset Quotes erd
\end_inset

 to represent a mapping over the course of 
\begin_inset Quotes eld
\end_inset

training
\begin_inset Quotes erd
\end_inset

, wherein they are iteratively evaluated on sample data while a 
\begin_inset Quotes eld
\end_inset

learning rule
\begin_inset Quotes erd
\end_inset

 periodically updates the parameters (
\emph on
weights
\emph default
) that parameterize the DNN.
 In recent years they have been investigated for near real-time scientific
 use cases 
\begin_inset CommandInset citation
LatexCommand cite
key "liu2019deep,patton2018167,liu2022exploring"
literal "false"

\end_inset

 but their use for the lowest latency use cases has been very limited 
\begin_inset CommandInset citation
LatexCommand cite
key "Duarte_2018"
literal "false"

\end_inset

.
 The reasons for this are threefold: 
\end_layout

\begin_layout Enumerate
Graphics Processing Units (GPUs), the conventional hardware target for DNNs,
 until very recently, have not been performant enough for these very high
 data rate, very low latency, use cases (due to their low clock speeds and
 low peripheral bandwidth 
\begin_inset CommandInset citation
LatexCommand cite
key "aaij2020allen"
literal "false"

\end_inset

);
\end_layout

\begin_layout Enumerate
DNNs, by virtue of their depth, are resource intensive, in terms of both
 memory (for the weights) and compute (floating point arithmetic), thereby
 preventing their deployment to FPGAs, which, in particular, have limited
 static RAM available;
\end_layout

\begin_layout Enumerate
DNNs are (typically) defined, trained, and distributed using high-level
 frameworks (such as PyTorch 
\begin_inset CommandInset citation
LatexCommand cite
key "paszke2017automatic"
literal "false"

\end_inset

, TensorFlow 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1603.04467"
literal "false"

\end_inset

, MXNet 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1512.01274"
literal "false"

\end_inset

), which abstract all implementation details from the user, thereby making
 portability of existing model architectures (to e.g., FPGA) nigh impossible.
\end_layout

\begin_layout Standard
These three barriers demand of a solution that can simultaneously translate
 a high-level representation of a DNN to a low-level representation, suitable
 for deployment to FPGA, while optimizing resource usage and minimizing
 latency.
 In general, the task of 
\emph on
lowering
\emph default
 high-level representations of programs to lower-level representations is
 the domain of a compiler.
 Similarly, the task of 
\emph on
synthesizing
\emph default
 a
\emph on
 register-transfer level
\emph default
 (RTL) 
\emph on
design
\emph default
, rendered in a 
\emph on
hardware description language
\emph default
 (HDL), from a program, is the domain of high-level synthesis (HLS) 
\begin_inset CommandInset citation
LatexCommand cite
key "7368920"
literal "false"

\end_inset

.
 While several such HLS tools exist 
\begin_inset CommandInset citation
LatexCommand cite
key "10.1145/2514740,Zhang2008,ferrandi2021bambu"
literal "false"

\end_inset

 and despite, often, bundling robust optimizing compilers, they struggle
 to effectively perform the necessary optimizations in reasonable amounts
 of time (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Evaluation"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
\end_layout

\begin_layout Standard
Recently, deep learning compilers (such as TVM 
\begin_inset CommandInset citation
LatexCommand cite
key "chen2018tvm"
literal "false"

\end_inset

, MLIR 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.2002.11054"
literal "false"

\end_inset

, and Glow 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1805.00907"
literal "false"

\end_inset

) have demonstrated the ability to dramatically reduce inference latencies
 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1809.02697"
literal "false"

\end_inset

, training times 
\begin_inset CommandInset citation
LatexCommand cite
key "9664259"
literal "false"

\end_inset

, and memory usage 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1604.06174"
literal "false"

\end_inset

 of DNNs.
 These compilers function by extracting intermediate-level representations
 (IRs) of the DNNs, from the representations produced by the frameworks,
 and performing various optimizations on those IRs (such as kernel fusion
 
\begin_inset CommandInset citation
LatexCommand cite
key "10.1145/2858788.2688521"
literal "false"

\end_inset

, vectorization 
\begin_inset CommandInset citation
LatexCommand cite
key "maleki2011evaluation"
literal "false"

\end_inset

, and memory planning 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1604.06174"
literal "false"

\end_inset

).
 The highly optimized IR is then used to generate code for various target
 hardware platforms.
 Given the successes of these compilers, it's natural to wonder whether
 they can adapted to the task of sufficiently optimizing a DNN such that
 it might be synthesized to RTL, for deployment to FPGA.
\end_layout

\begin_layout Standard
In this paper, we present 
\family typewriter
BraggHLS
\family default
, an open source, lightweight, compiler and HLS framework which can lower
 DNNs defined as PyTorch models to FPGA implementations.
 
\family typewriter
BraggHLS
\family default
 uses a combination of compiler and HLS techniques to compile the entire
 DNN into a 
\emph on
statically scheduled
\emph default
 circuit, thereby eliminating all synchronization overheads and achieving
 ultra-low latency.
 
\family typewriter
BraggHLS
\family default
 is general and supports a wide range of DNN layer types, and thus a wide
 range of DNNs, but we evaluate it on a DNN designed for identifying Bragg
 diffraction peaks.
 In summary our specific contributions include:
\end_layout

\begin_layout Enumerate
We discuss the challenges faced by a compiler and HLS tool in attempting
 to lower DNNs to ultra-low latency designs, including runtime costs incurred
 during design space exploration, challenges meeting resource and timing
 constraints during synthesis, placement, and routing;
\end_layout

\begin_layout Enumerate
We describe and implement a compiler framework, 
\family typewriter
BraggHLS
\family default
, which can effectively transform unoptimized, hardware-agnostic PyTorch
 models into ultra-low latency RTL designs suitable for deployment to Xilinx
 FPGAs.
 
\family typewriter
BraggHLS
\family default
 is thoroughly tested, open source, and available at 
\begin_inset CommandInset href
LatexCommand href
name "https://github.com/makslevental/bragghls/"
target "https://github.com/makslevental/bragghls/"
literal "false"

\end_inset

;
\end_layout

\begin_layout Enumerate
We show that designs generated by 
\family typewriter
BraggHLS
\family default
 achieve lower latency than Xilinx's state-of-the-art commercial HLS tool
 (Vitis HLS) for a variety of DNN layer types.
 In particular we show that 
\family typewriter
BraggHLS
\family default
 can produce synthesizable designs that meet placement, routing, and timing
 constraints, where Vitis HLS cannot.
\end_layout

\begin_layout Standard
The rest of this paper is organized as follows: Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Background"

\end_inset

 reviews key concepts from compilers, high-level synthesis, and FPGA design
 flows.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:BraggHLS-compiler-and"

\end_inset

 describes the 
\family typewriter
BraggHLS
\family default
 compiler and HLS framework in detail.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Evaluation"

\end_inset

 describes 
\family typewriter
BraggNN
\family default
, the Bragg peak detection DNN, and evaluates 
\family typewriter
BraggHLS
\family default
’s resource efficiency, scalability, and competitiveness with designs generated
 by Vitis HLS.
 Finally, Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Conclusion"

\end_inset

 concludes with a summary, and related and future work.
\end_layout

\begin_layout Section
Background
\begin_inset CommandInset label
LatexCommand label
name "sec:Background"

\end_inset


\end_layout

\begin_layout Subsection
Compilers: the path from high to low
\end_layout

\begin_layout Standard
The path from a high-level, abstract, representations of a DNN to a register-tra
nsfer level representation can be neatly formulated as a series of progressive
 lowerings between adjacent levels of abstraction.
 Each level of abstraction is rendered as a programming language, IR, or
 HDL and thus we descibe each lowering in terms these representations and
 the tools that manipulate them:
\end_layout

\begin_layout Enumerate
An imperative, 
\emph on
define-by-run,
\emph default
 Python representation, in PyTorch;
\end_layout

\begin_layout Enumerate
High-level data-flow graph representation, in TorchScript;
\end_layout

\begin_layout Enumerate
Low-level data and control flow graph representation, in MLIR.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsubsection
PyTorch and TorchScript
\end_layout

\begin_layout Standard
Typically DNN models are represented in terms of high-level frameworks,
 themselves implemented within general purpose programming languages.
 Such frameworks are widely used because of their ease of use and large
 library of example implementations of various DNN model architectures.
 Since 
\family typewriter
BraggNN
\family default
 is implemented using PyTorch, we focus on relevant aspects of PyTorch.
 DNNs developed within PyTorch are 
\emph on
defined-by-run
\emph default
: the author imperatively describes the DNN in terms of high-level operations,
 using python, which when executed materializes the high-level data-flow
 graph (DFG) corresponding to the DNN (e.g., for the purposes of reverse-mode
 automatic differentiation).
 From the perspective of the user, define-by-run enables fast iteration
 at development time, possibly at the cost of some runtime performance.
 
\end_layout

\begin_layout Standard
From the perspective of compilation, define-by-run precludes efficient extractio
n of the high-level DFG; since the DFG is materialized only at runtime,
 it cannot be inferred from the textual representation (i.e., the python source)
 of the DNN.
 Furthermore, apriori, the runtime-materialized DFG is only partially materializ
ed
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Quotes eld
\end_inset

...instead, every intermediate result records only the subset of the computation
 graph that was relevant to their computation.
\begin_inset Quotes erd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "paszke2017automatic"
literal "false"

\end_inset


\end_layout

\end_inset

, and only as an in-memory data structure.
 Thus, framework support is necessary.
 Indeed, PyTorch supports a Single Static Assignment (SSA) IR, called TorchScrip
t (TS) IR and accompanying tracing mechanism (the TS JIT) to produce TS
 IR from conventionally defined PyTorch models.
 Lowering from PyTorch to TS IR enables various useful analyses and transformati
ons on a DNN at the level of the high-level DFG (such as kernel fusion 
\begin_inset CommandInset citation
LatexCommand cite
key "10.1145/2858788.2688521"
literal "false"

\end_inset

) but targeting FPGAs requires a broader collection of transformations.
 To this end, we turn to a recent addition to the compiler ecosystem.
\end_layout

\begin_layout Subsubsection
MLIR
\end_layout

\begin_layout Standard
Multi-level Intermediate Representation 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.2002.11054"
literal "false"

\end_inset

 presents a new approach to building reusable and extensible compiler infrastruc
ture.
 MLIR is composed of a set of 
\emph on
dialect
\emph default
 IRs, subsets of which are mutually compatible, either outright or by way
 of translation/legalization.
 The various dialects aim to capture and formalize the semantics of compute
 intensive programs at varying levels of abstraction, as well as namespace
 related sets of IR transformations.
 The entrypoint into this compiler framework, from PyTorch, is the 
\family typewriter
torch
\family default
 dialect 
\begin_inset CommandInset citation
LatexCommand cite
key "torch-mlir"
literal "false"

\end_inset

, a high-fidelity mapping from TS IR to MLIR native IR, which, in addition
 to performing the translation to MLIR, fully refines all shapes of intermediate
 tensors in the DNN (i.e., computes concrete values for all dimensions of
 each tensor); this is necessary for downstream optimizations and eliminating
 inconsistencies 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.2203.08402"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
While the 
\family typewriter
torch
\family default
 dialect is necessary for lowering to MLIR and shape refinement, it is a
 representation of a DNN at the same level of abstraction as TS IR: it does
 not capture the precise data flow and control flow necessary for novel
 implementations of DNN operations (e.g., for FPGA).
 Fortunately, MLIR supports lower-level dialects, such as the 
\family typewriter
affine
\family default
 and 
\family typewriter
scf
\family default
 (structured control flow) dialects.
 The 
\family typewriter
scf
\family default
 is a straightforward formalization of control flow primitives, such as
 conditionals and loops, so we do not discuss it in great detail.
 The 
\family typewriter
affine
\family default
 dialect, on the otherhand, provides a formalization of semantics that lend
 themselves to polyhedral compilation techniques 
\begin_inset CommandInset citation
LatexCommand cite
key "polyhedral-mlir"
literal "false"

\end_inset

, i.e., techniques that make dependence analysis and loop transformations
 efficient and reliable.
 We discuss the importance of loop transformations in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:BraggHLS-compiler-and"

\end_inset

.
\end_layout

\begin_layout Subsection
High-level synthesis and FPGA design
\end_layout

\begin_layout Subsubsection
High-level synthesis
\end_layout

\begin_layout Standard
High-level synthesis tools produce RTL descriptions of digital designs from
 high-level representations, such as C or C++ 
\begin_inset CommandInset citation
LatexCommand cite
key "10.1145/2514740,ferrandi2021bambu"
literal "false"

\end_inset

 or LLVM IR.
 In particular, Xilinx's Vitis HLS, based on the Autopilot project 
\begin_inset CommandInset citation
LatexCommand cite
key "Zhang2008"
literal "false"

\end_inset

, recently enabled passing LLVM IR to the tool, rather than C/C++.
 Given a high-level, procedural, representation, HLS proceeds in three steps,
 in order to produce a corresponding RTL design:
\end_layout

\begin_layout Enumerate
HLS schedules operations (such as 
\family typewriter
fmul
\family default
, 
\family typewriter
fadd
\family default
, 
\family typewriter
load
\family default
, 
\family typewriter
store
\family default
) in order to determine which operations should occur during each clock-cycle.
 Such a schedule depends on three characteristics of the high-level representati
on:
\end_layout

\begin_deeper
\begin_layout Enumerate
The topological ordering of the DFG/CFG of the procedural representation
 (i.e., the dependencies of operations on results of other operations and
 resources);
\end_layout

\begin_layout Enumerate
The completion time for each operation;
\end_layout

\begin_layout Enumerate
The user's desired clock rate/frequency;
\end_layout

\end_deeper
\begin_layout Enumerate
HLS associates operations to particular RTL instantiations (called 
\emph on
binding
\emph default
) for those operations; for example whether to associate an add operation
 followed by a multiply operation to two separate instances, or whether
 to associate them both with a single instance (e.g., configured to perform
 a fused-multiply-add);
\end_layout

\begin_layout Enumerate
HLS builds an finite-state machine (FSM) that functions as control logic
 for the sequence of operations in the schedule.
\end_layout

\begin_layout Standard
In addition to fulfilling these three fundamental tasks, high-level synthesis
 tools such perform standard compiler optimization passes on the IR (that
 they ingest or produce internally).
 Optimization passes such as store-load forwarding, common subexpression
 elimination, and constant propagation, loop-unrolling and tiling.
 Note that these optimization passes exhibit varying levels of runtime complexit
y, e.g., store-load forwarding in combination with loop-unrolling is polynomial
 in the 
\begin_inset Quotes eld
\end_inset

trip-count
\begin_inset Quotes erd
\end_inset

 of the loop nest.
 Note also that the scheduling problem solved by HLS is reducible an integer
 linear programming problem (ILP), instances of which are NP-hard in general.
 Thus, HLS tools solve computationally intensive problems in order to produce
 a RTL description of a high-level representation of a DNN.
 These 
\begin_inset Quotes eld
\end_inset

development time
\begin_inset Quotes erd
\end_inset

 costs (i.e., runtime of the tools) impose practical limitations on the amount
 of design space exploration (for the purpose of achieving latency goals)
 which can be performed.
 
\end_layout

\begin_layout Subsection
FPGA design
\end_layout

\begin_layout Standard
At the RTL level of abstraction, there remain two more steps prior to being
 able to actually deploy to an FPGA; one of them being a final lowering,
 so called logic synthesis, and the other being place and route (P&R).
 Logic synthesis is the process of mapping RTL to actual hardware primitives
 on the FPGA (so-called 
\emph on
technology mapping
\emph default
), such as lookup tables (LUTs), block RAMs (BRAMs), flip-flops (FFs), and
 digital signal processors (DSPs).
 Logic synthesis produces a network list (
\emph on
netlist
\emph default
) describing the logical connectivity of various parts of the design.
 Logic synthesis effectively determines the implementation of floating point
 operations in terms of DSPs; depending on user parameters and other design
 features, DSP resource consumption for floating point multiplication and
 addition can differ greatly.
 The number of LUTs and DSPs that a high-level representation of a DNN correspon
ds to is relevant to both the performance and feasibility of that DNN when
 deployed to FPGA.
\end_layout

\begin_layout Standard
After the netlist has been produced, the entire design undergoes P&R.
 The goal of P&R is to determine which configurable logic block within an
 FPGA should implement each of the units of logic required by the digital
 design.
 P&R algorithms need to minimize distances between related units of functionalit
y (in order to minimize wire delay), balance wire density across the entire
 fabric of the FPGA (in order to reduce route congestion), and maximize
 the clock speed of the design (a function of both wire delay, logic complexity,
 and route congestion).
 The final, routed design, can then be deployed to the FPGA by producing
 a proprietary 
\emph on
bitstream
\emph default
, which is written to the FPGA.
\end_layout

\begin_layout Section

\family typewriter
BraggHLS
\family default
 compiler and HLS framework
\begin_inset CommandInset label
LatexCommand label
name "sec:BraggHLS-compiler-and"

\end_inset


\end_layout

\begin_layout Section
Evaluation
\begin_inset CommandInset label
LatexCommand label
name "sec:Evaluation"

\end_inset


\end_layout

\begin_layout Standard
asdasd
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /Users/mlevental/dev_projects/hls_paper/data/cpps/addmm.pdf
	lyxscale 50
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\family typewriter
addmm
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "2dlattice-1-1-2"

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /Users/mlevental/dev_projects/hls_paper/data/cpps/braggnn.pdf
	lyxscale 50
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\family typewriter
braggnn
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "2dlattice-1-2-2"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset CommandInset label
LatexCommand label
name "2dlattice-1-3"

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /Users/mlevental/dev_projects/hls_paper/data/cpps/conv.pdf
	lyxscale 50
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\family typewriter
conv
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "2dlattice-1-1-1-1"

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /Users/mlevental/dev_projects/hls_paper/data/cpps/matmul.pdf
	lyxscale 50
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\family typewriter
matmul
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "2dlattice-1-2-1-1"

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Resource usage and latency vs.
 unroll factor of various DNN modules.
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /Users/mlevental/dev_projects/hls_paper/data/cpps/elapsed_time.pdf
	lyxscale 50
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Runtime of Vitis HLS vs.
 unroll factor.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusion
\begin_inset CommandInset label
LatexCommand label
name "sec:Conclusion"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Remember though that your final submission is supposed to have all the bibliogra
phy entries embedded in the \SpecialChar LaTeX
-file.
 This means you eventually have to copy the .bbl file into the latex file
 and remove the bibtex lines.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "ref"
options "IEEEtran"

\end_inset


\end_layout

\end_body
\end_document
