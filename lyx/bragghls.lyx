#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass IEEEtran
\begin_preamble
% for subfigures/subtables
\usepackage[caption=false,font=footnotesize]{subfig}
\end_preamble
\options conference
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package none
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures false
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command bibtex
\index_command default
\float_placement tbh
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_title "Your Title"
\pdf_author "Your Name"
\pdf_bookmarks true
\pdf_bookmarksnumbered true
\pdf_bookmarksopen true
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle false
\pdf_quoted_options "pdfpagelayout=OneColumn, pdfnewwindow=true, pdfstartview=XYZ, plainpages=false"
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\family typewriter
BraggHLS
\end_layout

\begin_layout Author
\begin_inset Flex Author Name
status open

\begin_layout Plain Layout
Maksim
\begin_inset space ~
\end_inset

Levental
\end_layout

\end_inset


\begin_inset Flex Author Affiliation
status open

\begin_layout Plain Layout
University of Chicago
\begin_inset Newline newline
\end_inset

Email: test@test.tes
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
and 
\end_layout

\end_inset


\begin_inset Flex Author Name
status open

\begin_layout Plain Layout
Ryan
\begin_inset space ~
\end_inset

Chard
\end_layout

\end_inset


\begin_inset Flex Author Affiliation
status open

\begin_layout Plain Layout
Ecole Superieure
\begin_inset Newline newline
\end_inset

Nantes, France
\begin_inset Newline newline
\end_inset

Email: second@second.fr
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
and 
\end_layout

\end_inset


\begin_inset Flex Author Name
status open

\begin_layout Plain Layout
Kyle
\begin_inset space ~
\end_inset

Chard
\begin_inset Newline newline
\end_inset

and Ian
\begin_inset space ~
\end_inset

Foster
\end_layout

\end_inset


\begin_inset Flex Author Affiliation
status collapsed

\begin_layout Plain Layout
Star Academy
\begin_inset Newline newline
\end_inset

San Francisco, California 99999-9999
\begin_inset Newline newline
\end_inset

Telephone: (800) 555–5555
\begin_inset Newline newline
\end_inset

Fax: (888) 555–5555
\end_layout

\end_inset


\end_layout

\begin_layout Abstract
In many experiment-driven scientific domains, such as high-energy physics,
 material science, and cosmology, very high data rate experiments impose
 hard constraints on the corresponding data acquisition systems: collected
 data must either be indiscriminately stored for post-processing and analysis,
 thereby necessitating large storage capacity, or accurately filtered in
 real-time, thereby necessitating low latency execution.
 Deep neural networks, effective in many other filtering tasks, have not
 been widely employed in such data acquisition systems, due to design and
 deployment difficulties.
 This paper presents an open source, lightweight, compiler framework 
\family typewriter
BraggHLS
\family default
, based on high-level synthesis techniques, for translating high-level represent
ations of deep neural networks to low-level representations, suitable for
 deployment to near-sensor devices such as field-programmable gate arrays.
 We present a case study and evaluation of 
\family typewriter
BraggHLS
\family default
 on a deep neural network for Bragg peak detection in the context of high-energy
 diffraction microscopy.
 We show 
\family typewriter
BraggHLS
\family default
 is able to produce an implementation with a throughput 4.7µs/sample, which
 is approximately a 5x improvement over the existing implementation.
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Very high data rates are observed and large datasets are, consequently,
 generated across a broad range of experiments in scientific domains such
 as high-energy physics, material science, and cosmology.
 For example, in high-energy physics, the LHCb detector, at the CERN Large
 Hadron Collider, is tasked with observing the trajectories of particles
 produced in proton-proton collisions at a rate of 40 million per second
 (i.e., 40 MHz) 
\begin_inset CommandInset citation
LatexCommand cite
key "pmlr-v42-glig14"
literal "false"

\end_inset

.
 At a packet size of approximately 50kB (per collision), this implies a
 data rate of approximately 2TB/s.
 Ultimately, in combination with the other detectors, the LHC processes
 approximately 100EB of data a year.
 In materials science, High-Energy Diffraction Microscopy (HEDM) techniques,
 which provide non-destructive characterization of structure and its evolution
 in a broad class of single-crystal and polycrystalline materials, can have
 collection rates approaching 1 MHz 
\begin_inset CommandInset citation
LatexCommand cite
key "Hammer_2021"
literal "false"

\end_inset

, with a corresponding packet size of 80kB.
 In cosmology, the Square Kilometre Array, a radio telescope projected to
 be completed in 2024 and to be operational by 2027 
\begin_inset CommandInset citation
LatexCommand cite
key "mcmullin2022square"
literal "false"

\end_inset

, will sustain data rates in excess of 10 TB/s 
\begin_inset CommandInset citation
LatexCommand cite
key "grainge2017square"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Naturally, for high data rate experiments, directly storing and distributing
 such large quantities of data to the associated research communities for
 further analysis is cost prohibitive.
 Thus, either compression (in the case of storage and transmission) or outright
 filtering is employed, i.e., only a small fraction of the most 
\begin_inset Quotes eld
\end_inset

interesting
\begin_inset Quotes erd
\end_inset

 data is selected at time of collection, with the remainder being permanently
 discarded.
 In this work we focus on the filtering approach.
 Note, that the tradeoff made in employing filtering should be clear: reduced
 storage at the cost of stronger latency constraints (on the filtering mechanism
s).
 In addition, the risk of discarding significant data introduces accuracy
 (of the filtering mechanisms) as a critical new dimension of the data acquisiti
on systems.
 Typically, these filtering mechanisms consist either of physics based models
 
\begin_inset CommandInset citation
LatexCommand cite
key "LHCB-FIGURE-2020-018"
literal "false"

\end_inset

 or machine learning models 
\begin_inset CommandInset citation
LatexCommand cite
key "Gligorov_2013"
literal "false"

\end_inset

; in either case maximally efficient and effective use of the target hardware
 platform is tantamount to accuracy.
 Irrespective of the type of technique employed, almost universally, for
 the lowest latency constraint use cases (sub-microsecond), the technique
 is deployed to either field-programmable gate arrays (FPGAs) or application-spe
cific integrated circuits (ASICs) 
\begin_inset CommandInset citation
LatexCommand cite
key "Duarte_2018"
literal "false"

\end_inset

.
 The reason for this is only FPGAs and ASICs are flexible enough to satisfy
 the latency constraints for a wide range of techniques.
 Note, in this work we focus exclusively on FPGAs.
\end_layout

\begin_layout Standard
Deep neural networks (DNNs), a particular type of machine learning model,
 have been shown to be effective in many scientific and commercial domains
 due to their 
\begin_inset Quotes eld
\end_inset

representational capacity
\begin_inset Quotes erd
\end_inset

, i.e., a capacity to (approximately) represent diverse sets of mappings 
\begin_inset CommandInset citation
LatexCommand cite
key "alzubaidi2021review"
literal "false"

\end_inset

.
 DNNs 
\begin_inset Quotes eld
\end_inset

learn
\begin_inset Quotes erd
\end_inset

 to represent a mapping over the course of 
\begin_inset Quotes eld
\end_inset

training
\begin_inset Quotes erd
\end_inset

, wherein they are iteratively applied to sample data while a 
\begin_inset Quotes eld
\end_inset

learning rule
\begin_inset Quotes erd
\end_inset

 periodically updates the parameters (
\emph on
weights
\emph default
) that parameterize the DNN.
 In recent years they have been investigated for near real-time scientific
 use cases 
\begin_inset CommandInset citation
LatexCommand cite
key "liu2019deep,patton2018167,liu2022exploring"
literal "false"

\end_inset

 but their use for the lowest latency use cases has been very limited 
\begin_inset CommandInset citation
LatexCommand cite
key "Duarte_2018"
literal "false"

\end_inset

.
 The reasons for this are threefold: 
\end_layout

\begin_layout Enumerate
Graphics Processing Units (GPUs), the conventional target platforms for
 DNNs, until very recently, have not been performant enough for these very
 high data rate, very low latency, use cases (due to their low clock speeds
 and low peripheral bandwidth 
\begin_inset CommandInset citation
LatexCommand cite
key "aaij2020allen"
literal "false"

\end_inset

).
\end_layout

\begin_layout Enumerate
DNNs, by virtue of being deep, are resource intensive, in terms of both
 memory (for the weights) and compute (floating point arithmetic), thereby
 preventing their deployment to FPGAs, which, in particular, have limited
 static RAM available.
\end_layout

\begin_layout Enumerate
DNNs are (typically) defined, trained, and distributed using high-level
 frameworks (such as PyTorch 
\begin_inset CommandInset citation
LatexCommand cite
key "paszke2017automatic"
literal "false"

\end_inset

, TensorFlow 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1603.04467"
literal "false"

\end_inset

, MXNet 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1512.01274"
literal "false"

\end_inset

), which abstract all implementation details from the user, thereby making
 portability of existing model architectures (to e.g., FPGA) nigh impossible.
\end_layout

\begin_layout Standard
These above three barriers demand of a solution that can simultaneously
 translate a high-level representation of a DNN to a low-level representation,
 suitable for deployment to FPGA, while optimizing resource usage and minimizing
 latency.
 In general, the task of 
\emph on
lowering
\emph default
 high-level representations of programs to lower-level representations is
 the domain of a compiler.
 Correspondingly, the task of 
\emph on
synthesizing
\emph default
 a
\emph on
 register-transfer level
\emph default
 (RTL) 
\emph on
design
\emph default
, rendered in a 
\emph on
hardware description language
\emph default
 (HDL), from a program, is the domain of high-level synthesis (HLS) 
\begin_inset CommandInset citation
LatexCommand cite
key "7368920"
literal "false"

\end_inset

.
 While several such HLS tools exist 
\begin_inset CommandInset citation
LatexCommand cite
key "10.1145/2514740,Zhang2008,ferrandi2021bambu"
literal "false"

\end_inset

 and despite, often, bundling robust optimizing compilers, it turns out
 they struggle to effectively perform the necessary optimizations (see Section
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Evaluation"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
\end_layout

\begin_layout Standard
Recently, deep learning compilers (such as TVM 
\begin_inset CommandInset citation
LatexCommand cite
key "chen2018tvm"
literal "false"

\end_inset

, MLIR 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.2002.11054"
literal "false"

\end_inset

, and Glow 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1805.00907"
literal "false"

\end_inset

) have demonstrated the ability to dramatically reduce inference latencies
 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1809.02697"
literal "false"

\end_inset

, training times 
\begin_inset CommandInset citation
LatexCommand cite
key "9664259"
literal "false"

\end_inset

, and memory usage 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1604.06174"
literal "false"

\end_inset

 of DNNs.
 These compilers function by extracting intermediate-level representations
 (IRs) of the DNNs, from the representations produced by the frameworks,
 and performing various optimizations on those IRs (such as kernel fusion
 
\begin_inset CommandInset citation
LatexCommand cite
key "10.1145/2858788.2688521"
literal "false"

\end_inset

, vectorization 
\begin_inset CommandInset citation
LatexCommand cite
key "maleki2011evaluation"
literal "false"

\end_inset

, and memory planning 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1604.06174"
literal "false"

\end_inset

).
 The highly optimized IR is then used to generate code for various target
 architectures.
 Given the successes of these compilers, it's natural to wonder whether
 they can adapted to the task of sufficiently optimizing DNNs such that
 they might synthesized to RTL for deployment to FPGA (thus made suitable
 for the lowest latency use cases).
 
\end_layout

\begin_layout Standard
In this paper, we present 
\family typewriter
BraggHLS
\family default
, an open source, lightweight, compiler and HLS framework which can lower
 DNNs defined as PyTorch models to FPGA implementations.
 
\family typewriter
BraggHLS
\family default
 uses a combination of compiler and HLS techniques to compile the entire
 DNN into a 
\emph on
synchronous
\emph default
 module/circuit/design, thereby eliminating all synchronization resource
 overheads and achieving ultra-low latency.
 
\family typewriter
BraggHLS
\family default
 is general and supports a wide range of DNN layer types, and thus a wide
 range of DNNs, but we evaluate it on a DNN designed for identifying Bragg
 diffraction peaks.
 In summary our specific contributions include:
\end_layout

\begin_layout Enumerate
We discuss the challenges faced by a compiler and HLS tool in attempting
 to lower DNNs to ultra-low latency designs, including runtime costs incurred
 during design space exploration, challenges meeting resource and timing
 constraints during synthesis, placement, and routing.
\end_layout

\begin_layout Enumerate
We describe and implement a compiler framework, 
\family typewriter
BraggHLS
\family default
, which can effectively transform unoptimized, hardware-agnostic PyTorch
 models into ultra-low latency RTL designs suitable for deployment to Xilinx
 FPGAs.
 
\family typewriter
BraggHLS
\family default
 is thoroughly tested, open source, and available at 
\begin_inset CommandInset href
LatexCommand href
name "https://github.com/makslevental/bragghls/"
target "https://github.com/makslevental/bragghls/"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate
We show that designs generated by 
\family typewriter
BraggHLS
\family default
 achieve lower latency than Xilinx's state-of-the-art commercial HLS tool
 (Vitis HLS) for a variety of DNN layer types.
 In particular we show that 
\family typewriter
BraggHLS
\family default
 can produce synthesizable designs that meet placement, routing, and timing
 constraints where Vitis HLS cannot.
\end_layout

\begin_layout Standard
The rest of this paper is organized as follows: Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Background"

\end_inset

 reviews key concepts from compilers, scheduling, and FPGA synthesis, placement,
 and routing.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:BraggHLS-compiler-and"

\end_inset

 describes the 
\family typewriter
BraggHLS
\family default
 compiler and HLS framework in detail.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Evaluation"

\end_inset

 describes the Bragg peak detection DNN and evaluates 
\family typewriter
BraggHLS
\family default
’s resource efficiency, scalability, and competitiveness with designs generated
 by Vitis HLS.
 Finally, Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Conclusion"

\end_inset

 concludes with a summary, and related and future work.
\end_layout

\begin_layout Section
Background
\begin_inset CommandInset label
LatexCommand label
name "sec:Background"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
A convenient byproduct of this procedure is that the DNN becomes decoupled
 from the framework while remaining computable (insofar as it is adequately
 described by the IR).
 In particular, given a compiler that can produce an IR which represents
 the various deep learning layers (such as convolution, linear, normalization,
 activation layers) as loop nests, it is possible to further extract control
 flow and data flow graphs (CFG, DFG) from the IR.
 Given the CFG and DFG of a DNN
\end_layout

\begin_layout Plain Layout
IR and (depending on the compiler) can be 
\end_layout

\begin_layout Plain Layout
In this paper, we focus on an open source, lightweight, compiler framework
 
\family typewriter
BraggHLS
\end_layout

\begin_layout Plain Layout
For example, BraggNN, a DNN aimed at identifying Bragg diffraction peaks
 with high precision, has been shown to make peak position determinations
 with high accuracy.
 Still, as of yet DNN models have not seen wide adoption in this area.
 This is due to the limitations imposed by the hardware platforms on which
 they can typically be deployed: GPUs and other such DNN accelerators.
 Primarily, such accelerators do not meet the hard real-time latency constraints
, and secondarily they cannot be easily colocated with complex sensing apparatus
es.
 BraggNN, despite having been shown to have high speedup over the classical
 pseudo-Voigt peak fitting methods, making determinations in approximately
 700µs, still falls short of the 1µs target for handling 1MHz sampling rates.
 In addition, the current implementation of BraggNN, deployed to either
 a datacenter class GPU such as a NVIDIA V100, or even a workstation class
 GPU such as a NVIDIA RTX 2080Ti, has no practicable means to being deployed
 at the edge, i.e., adjacent or proximal to the high energy microscopy equipment.
\end_layout

\end_inset


\end_layout

\begin_layout Section

\family typewriter
BraggHLS
\family default
 compiler and HLS framework
\begin_inset CommandInset label
LatexCommand label
name "sec:BraggHLS-compiler-and"

\end_inset


\end_layout

\begin_layout Section
Evaluation
\begin_inset CommandInset label
LatexCommand label
name "sec:Evaluation"

\end_inset


\end_layout

\begin_layout Standard
asdasd
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /home/mlevental/dev_projects/hls_paper/data/cpps/addmm.pdf
	lyxscale 50
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\family typewriter
addmm
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "2dlattice-1-1-2"

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /home/mlevental/dev_projects/hls_paper/data/cpps/braggnn.pdf
	lyxscale 50
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\family typewriter
braggnn
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "2dlattice-1-2-2"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset CommandInset label
LatexCommand label
name "2dlattice-1-3"

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /home/mlevental/dev_projects/hls_paper/data/cpps/conv.pdf
	lyxscale 50
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\family typewriter
conv
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "2dlattice-1-1-1-1"

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /home/mlevental/dev_projects/hls_paper/data/cpps/matmul.pdf
	lyxscale 50
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\family typewriter
matmul
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "2dlattice-1-2-1-1"

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Resource usage and latency vs.
 unroll factor of various DNN modules.
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /home/mlevental/dev_projects/hls_paper/data/cpps/elapsed_time.pdf
	lyxscale 50
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Runtime of Vitis HLS vs.
 unroll factor.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusion
\begin_inset CommandInset label
LatexCommand label
name "sec:Conclusion"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Remember though that your final submission is supposed to have all the bibliogra
phy entries embedded in the \SpecialChar LaTeX
-file.
 This means you eventually have to copy the .bbl file into the latex file
 and remove the bibtex lines.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "ref"
options "IEEEtran"

\end_inset


\end_layout

\end_body
\end_document
