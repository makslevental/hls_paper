#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass IEEEtran
\begin_preamble
% for subfigures/subtables
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{hyperref}
\hypersetup{colorlinks=true}
\usepackage[dvipsnames]{xcolor}
\definecolor{lgray}{rgb}{0.95, 0.95, 0.95}
\end_preamble
\options conference
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package none
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures false
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command bibtex
\index_command default
\float_placement tbh
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_title "Your Title"
\pdf_author "Your Name"
\pdf_bookmarks true
\pdf_bookmarksnumbered true
\pdf_bookmarksopen true
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle false
\pdf_quoted_options "pdfpagelayout=OneColumn, pdfnewwindow=true, pdfstartview=XYZ, plainpages=false"
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\family typewriter
BraggHLS
\end_layout

\begin_layout Author
\begin_inset Flex Author Name
status open

\begin_layout Plain Layout
Maksim
\begin_inset space ~
\end_inset

Levental
\end_layout

\end_inset


\begin_inset Flex Author Affiliation
status open

\begin_layout Plain Layout
University of Chicago
\begin_inset Newline newline
\end_inset

Email: test@test.tes
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
and 
\end_layout

\end_inset


\begin_inset Flex Author Name
status open

\begin_layout Plain Layout
Ryan
\begin_inset space ~
\end_inset

Chard
\end_layout

\end_inset


\begin_inset Flex Author Affiliation
status open

\begin_layout Plain Layout
Ecole Superieure
\begin_inset Newline newline
\end_inset

Nantes, France
\begin_inset Newline newline
\end_inset

Email: second@second.fr
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
and 
\end_layout

\end_inset


\begin_inset Flex Author Name
status open

\begin_layout Plain Layout
Kyle
\begin_inset space ~
\end_inset

Chard
\begin_inset Newline newline
\end_inset

and Ian
\begin_inset space ~
\end_inset

Foster
\end_layout

\end_inset


\begin_inset Flex Author Affiliation
status collapsed

\begin_layout Plain Layout
Star Academy
\begin_inset Newline newline
\end_inset

San Francisco, California 99999-9999
\begin_inset Newline newline
\end_inset

Telephone: (800) 555–5555
\begin_inset Newline newline
\end_inset

Fax: (888) 555–5555
\end_layout

\end_inset


\end_layout

\begin_layout Abstract
In many experiment-driven scientific domains, such as high-energy physics,
 material science, and cosmology, very high data rate experiments impose
 hard constraints on the corresponding data acquisition systems: collected
 data must either be indiscriminately stored for post-processing and analysis,
 thereby necessitating large storage capacity, or accurately filtered in
 real-time, thereby necessitating low latency execution.
 Deep neural networks, effective in many other filtering tasks, have not
 been widely employed in such data acquisition systems, due to design and
 deployment difficulties.
 This paper presents an open source, lightweight, compiler framework 
\family typewriter
BraggHLS
\family default
, based on high-level synthesis techniques, for translating high-level represent
ations of deep neural networks to low-level representations, suitable for
 deployment to near-sensor devices such as field-programmable gate arrays.
 We present a case study and evaluation of 
\family typewriter
BraggHLS
\family default
 on a deep neural network for Bragg peak detection in the context of high-energy
 diffraction microscopy.
 We show 
\family typewriter
BraggHLS
\family default
 is able to produce an implementation with a throughput 4.7µs/sample, which
 is approximately a 5x improvement over the existing implementation.
\end_layout

\begin_layout Abstract
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Very high data rates are observed and, consequently, large datasets are
 generated across a broad range of experiments in scientific domains, such
 as high-energy physics, material science, and cosmology.
 For example, in high-energy physics, the LHCb detector, at the CERN Large
 Hadron Collider, is tasked with observing the trajectories of particles
 produced in proton-proton collisions at a rate of 40 million per second
 (i.e., 40 MHz) 
\begin_inset CommandInset citation
LatexCommand cite
key "pmlr-v42-glig14"
literal "false"

\end_inset

.
 With a packet size of approximately 50kB (per collision), this implies
 a data rate of approximately 2TB/s.
 Ultimately, in combination with other detectors, the LHC processes approximatel
y 100EB of data a year.
 In materials science, high-energy diffraction microscopy (HEDM) techniques,
 which provide non-destructive characterization of structure and its evolution
 in a broad class of single-crystal and polycrystalline materials, can have
 collection rates approaching 1 MHz 
\begin_inset CommandInset citation
LatexCommand cite
key "Hammer_2021"
literal "false"

\end_inset

, with a corresponding packet size of 80kB.
 In cosmology, the Square Kilometre Array, a radio telescope projected to
 be completed in 2024 and to be operational by 2027 
\begin_inset CommandInset citation
LatexCommand cite
key "mcmullin2022square"
literal "false"

\end_inset

, will sustain data rates in excess of 10 TB/s 
\begin_inset CommandInset citation
LatexCommand cite
key "grainge2017square"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Naturally, for high data rate experiments, directly storing and distributing
 such large quantities of data to the associated research communities for
 further analysis is cost prohibitive.
 Thus, either compression (in the case of storage and transmission) or outright
 filtering is necessary, i.e., only a small fraction of the most 
\begin_inset Quotes eld
\end_inset

interesting
\begin_inset Quotes erd
\end_inset

 data is selected at time of collection, with the remainder being permanently
 discarded.
 In this work we focus on the filtering approach.
 Note, that the tradeoff made in employing filtering should be clear: reduced
 storage at the expense of more stringent latency constraints (on the filtering
 mechanisms).
 In addition, the risk of discarding meaningful data introduces accuracy
 (of the filtering mechanisms) as a critical new dimension of the data acquisiti
on systems.
 Typically, these filtering mechanisms consist either of physics based models
 
\begin_inset CommandInset citation
LatexCommand cite
key "LHCB-FIGURE-2020-018"
literal "false"

\end_inset

 or machine learning models 
\begin_inset CommandInset citation
LatexCommand cite
key "Gligorov_2013"
literal "false"

\end_inset

; in either case maximally efficient and effective use of the target hardware
 platform is tantamount to accuracy.
 Irrespective of the type of technique employed, almost universally, for
 the ultra-low latency use cases (e.g., sub-microsecond latency constraints),
 the implementation is deployed to either field-programmable gate arrays
 (FPGAs) or application-specific integrated circuits (ASICs) 
\begin_inset CommandInset citation
LatexCommand cite
key "Duarte_2018"
literal "false"

\end_inset

.
 
\begin_inset Note Comment
status collapsed

\begin_layout Plain Layout
The reason for this is only FPGAs and ASICs are flexible enough to satisfy
 the latency constraints for a wide range of techniques.
 Note, in this work we focus exclusively on FPGAs.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Deep neural networks (DNNs), a particular type of machine learning model,
 have been shown to be effective in many scientific and commercial domains
 due to their 
\begin_inset Quotes eld
\end_inset

representational capacity
\begin_inset Quotes erd
\end_inset

, i.e., they demonstrate a capacity to (approximately) represent diverse sets
 of mappings 
\begin_inset CommandInset citation
LatexCommand cite
key "alzubaidi2021review"
literal "false"

\end_inset

.
 DNNs 
\begin_inset Quotes eld
\end_inset

learn
\begin_inset Quotes erd
\end_inset

 to represent a mapping over the course of 
\begin_inset Quotes eld
\end_inset

training
\begin_inset Quotes erd
\end_inset

, wherein they are iteratively evaluated on sample data while a 
\begin_inset Quotes eld
\end_inset

learning rule
\begin_inset Quotes erd
\end_inset

 periodically updates the parameters (
\emph on
weights
\emph default
) that parameterize the DNN.
 In recent years they have been investigated for near real-time scientific
 use cases 
\begin_inset CommandInset citation
LatexCommand cite
key "liu2019deep,patton2018167,liu2022exploring"
literal "false"

\end_inset

 but their use for the lowest latency use cases has been very limited 
\begin_inset CommandInset citation
LatexCommand cite
key "Duarte_2018"
literal "false"

\end_inset

.
 The reasons for this are threefold: 
\end_layout

\begin_layout Enumerate
Graphics Processing Units (GPUs), the conventional hardware target for DNNs,
 until very recently, have not been performant enough for these very high
 data rate, very low latency, use cases (due to their low clock speeds and
 low peripheral bandwidth 
\begin_inset CommandInset citation
LatexCommand cite
key "aaij2020allen"
literal "false"

\end_inset

);
\end_layout

\begin_layout Enumerate
DNNs, by virtue of their depth, are resource intensive, in terms of both
 memory (for the weights) and compute (floating point arithmetic), thereby
 preventing their deployment to FPGAs, which, in particular, have limited
 static RAM available;
\end_layout

\begin_layout Enumerate
DNNs are (typically) defined, trained, and distributed using high-level
 frameworks (such as PyTorch 
\begin_inset CommandInset citation
LatexCommand cite
key "paszke2017automatic"
literal "false"

\end_inset

, TensorFlow 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1603.04467"
literal "false"

\end_inset

, MXNet 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1512.01274"
literal "false"

\end_inset

), which abstract all implementation details from the user, thereby making
 portability of existing model architectures (to e.g., FPGA) nigh impossible.
\end_layout

\begin_layout Standard
These three barriers demand of a solution that can simultaneously translate
 a high-level representation of a DNN to a low-level representation, suitable
 for deployment to FPGA, while optimizing resource usage and minimizing
 latency.
 In general, the task of 
\emph on
lowering
\emph default
 high-level representations of programs to lower-level representations is
 the domain of a compiler.
 Similarly, the task of 
\emph on
synthesizing
\emph default
 a
\emph on
 register-transfer level
\emph default
 (RTL) 
\emph on
design
\emph default
, rendered in a 
\emph on
hardware description language
\emph default
 (HDL), from a program, is the domain of high-level synthesis (HLS) 
\begin_inset CommandInset citation
LatexCommand cite
key "7368920"
literal "false"

\end_inset

.
 While several such HLS tools exist 
\begin_inset CommandInset citation
LatexCommand cite
key "10.1145/2514740,Zhang2008,ferrandi2021bambu"
literal "false"

\end_inset

 and despite, often, bundling robust optimizing compilers, they struggle
 to effectively perform the necessary optimizations in reasonable amounts
 of time (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Evaluation"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
\end_layout

\begin_layout Standard
Recently, deep learning compilers (such as TVM 
\begin_inset CommandInset citation
LatexCommand cite
key "chen2018tvm"
literal "false"

\end_inset

, MLIR 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.2002.11054"
literal "false"

\end_inset

, and Glow 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1805.00907"
literal "false"

\end_inset

) have demonstrated the ability to dramatically reduce inference latencies
 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1809.02697"
literal "false"

\end_inset

, training times 
\begin_inset CommandInset citation
LatexCommand cite
key "9664259"
literal "false"

\end_inset

, and memory usage 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1604.06174"
literal "false"

\end_inset

 of DNNs.
 These compilers function by extracting intermediate-level representations
 (IRs) of the DNNs, from the representations produced by the frameworks,
 and performing various optimizations on those IRs (such as kernel fusion
 
\begin_inset CommandInset citation
LatexCommand cite
key "10.1145/2858788.2688521"
literal "false"

\end_inset

, vectorization 
\begin_inset CommandInset citation
LatexCommand cite
key "maleki2011evaluation"
literal "false"

\end_inset

, and memory planning 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.1604.06174"
literal "false"

\end_inset

).
 The highly optimized IR is then used to generate code for various target
 hardware platforms.
 Given the successes of these compilers, it's natural to wonder whether
 they can adapted to the task of sufficiently optimizing a DNN such that
 it might be synthesized to RTL, for deployment to FPGA.
\end_layout

\begin_layout Standard
In this paper, we present 
\family typewriter
BraggHLS
\family default
, an open source, lightweight, compiler and HLS framework which can lower
 DNNs defined as PyTorch models to FPGA implementations.
 
\family typewriter
BraggHLS
\family default
 uses a combination of compiler and HLS techniques to compile the entire
 DNN into a 
\emph on
statically scheduled
\emph default
 circuit, thereby eliminating all synchronization overheads and achieving
 ultra-low latency.
 
\family typewriter
BraggHLS
\family default
 is general and supports a wide range of DNN layer types, and thus a wide
 range of DNNs, but particularly focus on a DNN designed for identifying
 Bragg diffraction peaks.
 In summary our specific contributions include:
\end_layout

\begin_layout Enumerate
We discuss the challenges faced by a compiler and HLS tool in attempting
 to lower DNNs to ultra-low latency designs, including runtime costs incurred
 during design space exploration, challenges meeting resource and timing
 constraints during synthesis, placement, and routing;
\end_layout

\begin_layout Enumerate
We describe and implement a compiler framework, 
\family typewriter
BraggHLS
\family default
, which can effectively transform unoptimized, hardware-agnostic PyTorch
 models into ultra-low latency RTL designs suitable for deployment to Xilinx
 FPGAs.
 
\family typewriter
BraggHLS
\family default
 is thoroughly tested, open source, and available at 
\begin_inset CommandInset href
LatexCommand href
name "https://github.com/makslevental/bragghls/"
target "https://github.com/makslevental/bragghls/"
literal "false"

\end_inset

;
\end_layout

\begin_layout Enumerate
We show that designs generated by 
\family typewriter
BraggHLS
\family default
 achieve lower latency than Xilinx's state-of-the-art commercial HLS tool
 (Vitis HLS) for a variety of DNN layer types.
 In particular we show that 
\family typewriter
BraggHLS
\family default
 can produce synthesizable designs that meet placement, routing, and timing
 constraints, where Vitis HLS cannot.
\end_layout

\begin_layout Standard
The rest of this paper is organized as follows: Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Background"

\end_inset

 reviews key concepts from compilers, high-level synthesis, and FPGA design
 flows.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:BraggHLS-compiler-and"

\end_inset

 describes the 
\family typewriter
BraggHLS
\family default
 compiler and HLS framework in detail.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Evaluation"

\end_inset

 evaluates 
\family typewriter
BraggHLS
\family default
’s performance, scalability, and competitiveness with designs generated
 by Vitis HLS.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:BraggNN-case-study"

\end_inset

 describes our case study, 
\family typewriter
BraggHLS
\family default
 applied to 
\family typewriter
BraggNN
\family default
, a Bragg peak detection DNN with a target latency of 1µs/sample.
 Finally, Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Conclusion"

\end_inset

 concludes with a summary, and related and future work.
\end_layout

\begin_layout Section
Background
\begin_inset CommandInset label
LatexCommand label
name "sec:Background"

\end_inset


\end_layout

\begin_layout Subsection
Compilers: the path from high to low
\end_layout

\begin_layout Standard
The path from a high-level, abstract, representations of a DNN to a register-tra
nsfer level representation can be neatly formulated as a series of progressive
 lowerings between adjacent levels of abstraction.
 Each level of abstraction is rendered as a programming language, IR, or
 HDL, and thus we descibe each lowering in terms the representations and
 tools 
\family typewriter
BraggHLS
\family default
 employs:
\end_layout

\begin_layout Enumerate
An imperative, 
\emph on
define-by-run,
\emph default
 Python representation, in PyTorch;
\end_layout

\begin_layout Enumerate
High-level data-flow graph representation, in TorchScript;
\end_layout

\begin_layout Enumerate
Low-level data and control flow graph representation, in MLIR.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsubsection
PyTorch and TorchScript
\end_layout

\begin_layout Standard
Typically DNN models are represented in terms of high-level frameworks,
 themselves implemented within general purpose programming languages.
 Such frameworks are widely used because of their ease of use and large
 library of example implementations of various DNN model architectures.
 
\family typewriter
BraggHLS
\family default
 is implemented using PyTorch, thus we focus on relevant aspects of PyTorch.
 DNNs developed within PyTorch are 
\emph on
defined-by-run
\emph default
: the author imperatively describes the DNN in terms of high-level operations,
 using python, which when executed materializes the high-level data-flow
 graph (DFG) corresponding to the DNN (e.g., for the purposes of reverse-mode
 automatic differentiation).
 From the perspective of the user, define-by-run enables fast iteration
 at development time, possibly at the cost of some runtime performance.
 
\end_layout

\begin_layout Standard
From the perspective of compilation, define-by-run precludes efficient extractio
n of the high-level DFG; since the DFG is materialized only at runtime,
 it cannot be inferred from the textual representation (i.e., the python source)
 of the DNN.
 Furthermore, apriori, the runtime-materialized DFG is only partially materializ
ed
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Quotes eld
\end_inset

...instead, every intermediate result records only the subset of the computation
 graph that was relevant to their computation.
\begin_inset Quotes erd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "paszke2017automatic"
literal "false"

\end_inset


\end_layout

\end_inset

, and only as an in-memory data structure.
 Thus, framework support is necessary.
 Indeed, PyTorch supports a Single Static Assignment (SSA) IR, called TorchScrip
t (TS) IR and accompanying tracing mechanism (the TS JIT) to produce TS
 IR from conventionally defined PyTorch models.
 Lowering from PyTorch to TS IR enables various useful analyses and transformati
ons on a DNN at the level of the high-level DFG (such as kernel fusion 
\begin_inset CommandInset citation
LatexCommand cite
key "10.1145/2858788.2688521"
literal "false"

\end_inset

) but targeting FPGAs requires a broader collection of transformations.
 To this end, we turn to a recent addition to the compiler ecosystem.
\end_layout

\begin_layout Subsubsection
MLIR
\end_layout

\begin_layout Standard
Multi-level Intermediate Representation 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.2002.11054"
literal "false"

\end_inset

 presents a new approach to building reusable and extensible compiler infrastruc
ture.
 MLIR is composed of a set of 
\emph on
dialect
\emph default
 IRs, subsets of which are mutually compatible, either outright or by way
 of translation/legalization.
 The various dialects aim to capture and formalize the semantics of compute
 intensive programs at varying levels of abstraction, as well as namespace
 related sets of IR transformations.
 The entrypoint into this compiler framework, from PyTorch, is the 
\family typewriter
torch
\family default
 dialect 
\begin_inset CommandInset citation
LatexCommand cite
key "torch-mlir"
literal "false"

\end_inset

, a high-fidelity mapping from TS IR to MLIR native IR, which, in addition
 to performing the translation to MLIR, fully refines all shapes of intermediate
 tensors in the DNN (i.e., computes concrete values for all dimensions of
 each tensor); this is necessary for downstream optimizations and eliminating
 inconsistencies in the DNN 
\begin_inset CommandInset citation
LatexCommand cite
key "https://doi.org/10.48550/arxiv.2203.08402"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
While the 
\family typewriter
torch
\family default
 dialect is necessary for lowering to MLIR and shape refinement, it is a
 representation of a DNN at the same level of abstraction as TS IR: it does
 not capture the precise data flow and control flow necessary for novel
 implementations of DNN operations (e.g., for FPGA).
 Fortunately, MLIR supports lower-level dialects, such as the 
\family typewriter
affine
\family default
 and 
\family typewriter
scf
\family default
 (structured control flow) dialects.
 The 
\family typewriter
scf
\family default
 dialect is a straightforward formalization of control flow primitives,
 such as conditionals and loops.
 The 
\family typewriter
affine
\family default
 dialect, on the otherhand, provides a formalization of semantics that lend
 themselves to polyhedral compilation techniques 
\begin_inset CommandInset citation
LatexCommand cite
key "polyhedral-mlir"
literal "false"

\end_inset

, i.e., techniques that enable loop dependence analysis and loop transformations.
 Such loop transformations, particularly loop unrolling, are crucial for
 achieving lowest possible latencies 
\begin_inset CommandInset citation
LatexCommand cite
key "yehpca2022scalehls"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsection
High-level synthesis and FPGA design
\end_layout

\begin_layout Subsubsection
High-level synthesis
\begin_inset CommandInset label
LatexCommand label
name "subsec:High-level-synthesis"

\end_inset


\end_layout

\begin_layout Standard
High-level synthesis tools produce RTL descriptions of digital designs from
 high-level representations, such as C or C++ 
\begin_inset CommandInset citation
LatexCommand cite
key "10.1145/2514740,ferrandi2021bambu"
literal "false"

\end_inset

.
 In particular, Xilinx's Vitis HLS, based on the Autopilot project 
\begin_inset CommandInset citation
LatexCommand cite
key "Zhang2008"
literal "false"

\end_inset

, is a state-of-the-art HLS tool.
 Given a high-level, procedural, representation, HLS proceeds in three steps,
 in order to produce a corresponding RTL design:
\end_layout

\begin_layout Enumerate
HLS schedules operations (such as 
\family typewriter
mulf
\family default
, 
\family typewriter
addf
\family default
, 
\family typewriter
load
\family default
, 
\family typewriter
store
\family default
) in order to determine which operations should occur during each clock-cycle.
 Such a schedule depends on three characteristics of the high-level representati
on:
\end_layout

\begin_deeper
\begin_layout Enumerate
The topological ordering of the DFG/CFG of the procedural representation
 (i.e., the dependencies of operations on results of other operations and
 resources);
\end_layout

\begin_layout Enumerate
The completion time for each operation;
\end_layout

\begin_layout Enumerate
The user's desired clock rate/frequency;
\end_layout

\end_deeper
\begin_layout Enumerate
HLS associates operations to particular RTL instantiations (called 
\emph on
binding
\emph default
) for those operations; for example whether to associate an add operation
 followed by a multiply operation to two separate instances, or whether
 to associate them both with a single instance (e.g., configured to perform
 a fused-multiply-add);
\end_layout

\begin_layout Enumerate
HLS builds a finite-state machine (FSM) that implements the schedule of
 operations as control logic, i.e., logic that initiates operations and routes
 signals between them during the appropriate FSM stages.
\end_layout

\begin_layout Standard
In addition to fulfilling these three fundamental tasks, high-level synthesis
 aims to optimize the program, during synthesis.
 In particular, they try to maximize concurrency and parallelism (number
 of concurrent operations scheduled during a clock-cycle) in order maximize
 the throughput and minimize the latency of the final implementation.
 
\end_layout

\begin_layout Standard
Maximizing parallelism entails rigorous data-flow analysis in order to identify
 data dependencies that would lead to data hazards in synthesized designs.
 This data-flow analysis exhibits extremely high runtime as lower latency
 designs are pursued.
 This can be understood in terms of loop-nest representations of DNN operations;
 for example consider a convolution as in listing 
\begin_inset CommandInset ref
LatexCommand ref
reference "lis:Single-filter-convolution"

\end_inset

.
\begin_inset listings
lstparams "language=Python,float,fontsize={\footnotesize},escapeinside={||},mathescape=true"
inline false
status open

\begin_layout Plain Layout

def conv2d(
\end_layout

\begin_layout Plain Layout

  input: array(|$b$|, |$c_{in}$|, |$h$|, |$w$|),
\end_layout

\begin_layout Plain Layout

  output: array(|$b$|, |$c_{out}$|, |$h$|, |$w$|),
\end_layout

\begin_layout Plain Layout

  weight: array(|$c_{out}$|, |$c_{in}$|, |$k$|, |$k$|)
\end_layout

\begin_layout Plain Layout

):
\end_layout

\begin_layout Plain Layout

  for iv1 in range(0, |$b$|):
\end_layout

\begin_layout Plain Layout

    for iv2 in range(0, |$c_{out}$|):
\end_layout

\begin_layout Plain Layout

      for iv3 in range(0, |$h$|):
\end_layout

\begin_layout Plain Layout

        for iv4 in range(0, |$w$|):
\end_layout

\begin_layout Plain Layout

          for iv5 in range(0, |$c_{in}$|):
\end_layout

\begin_layout Plain Layout

            for iv6 in range(0, |$k$|):
\end_layout

\begin_layout Plain Layout

              for iv7 in range(0, |$k$|):
\end_layout

\begin_layout Plain Layout

                _3 = iv3 + iv6
\end_layout

\begin_layout Plain Layout

                _4 = iv4 + iv7
\end_layout

\begin_layout Plain Layout

                _5 = input[iv1, iv5, _3, _4]
\end_layout

\begin_layout Plain Layout

                _6 = weight[iv2, iv5, iv6, iv7]
\end_layout

\begin_layout Plain Layout

                _7 = output[iv1, iv2, iv3, iv4]
\end_layout

\begin_layout Plain Layout

                _8 = _5 * _6
\end_layout

\begin_layout Plain Layout

                _9 = _7 + _8
\end_layout

\begin_layout Plain Layout

                output[iv1, iv2, iv3, iv4] = _9
\begin_inset Caption Standard

\begin_layout Plain Layout
Padding 
\begin_inset Formula $\left\lfloor k/2\right\rfloor $
\end_inset

, stride 1, 
\begin_inset Formula $c_{out}$
\end_inset

 filter convolution with 
\begin_inset Formula $k\times k$
\end_inset

 kernel applied to (
\begin_inset Formula $\ensuremath{b},\ensuremath{c_{in}},\ensuremath{h},\ensuremath{w}$
\end_inset

)-dimensional
\family typewriter
 input
\family default
 tensor, where 
\begin_inset Formula $b$
\end_inset

 is the batch size, 
\begin_inset Formula $c_{in}$
\end_inset

 is the number of channels, and (
\begin_inset Formula $h,w$
\end_inset

) are the height and width, respectively.
\begin_inset CommandInset label
LatexCommand label
name "lis:Single-filter-convolution"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

 A schedule for the arithmetic operations for this loop nest can be computed
 by first unrolling all the loops up to some 
\begin_inset Quotes eld
\end_inset

trip-count
\begin_inset Quotes erd
\end_inset

 and then computing the topological sort of the operations (known as 
\emph on
list scheduling
\emph default
).
 The degree to which the loops are unrolled determines how many arithmetic
 operations can be scheduled in parallel.
 The issue is that the stores and loads on the 
\family typewriter
output
\family default
 array prevent reconstruction of explicit relationships between the inputs
 and outputs of the arithmetic operations across loop iterations.
 The standard resolution is to perform 
\emph on
store-load forwarding
\emph default
: pairs of store and load operations to/from the same memory address are
 eliminated, with the operand of the store forwarded to the uses of the
 load (see listing 
\begin_inset CommandInset ref
LatexCommand ref
reference "lis:Single-filter-convolution-1"

\end_inset

).
\begin_inset listings
lstparams "language=Python,float,numbers=left,fontsize={\footnotesize},escapeinside={||},mathescape=true,highlightlines={19,25}"
inline false
status open

\begin_layout Plain Layout

def conv2d(
\end_layout

\begin_layout Plain Layout

  input: array(|$b$|, |$c_{in}$|, |$h$|, |$w$|),
\end_layout

\begin_layout Plain Layout

  output: array(|$b$|, |$c_{out}$|, |$h$|, |$w$|),
\end_layout

\begin_layout Plain Layout

  weight: array(|$c_{out}$|, |$c_{in}$|, |$k$|, |$k$|)
\end_layout

\begin_layout Plain Layout

):
\end_layout

\begin_layout Plain Layout

  for iv1 in range(0, |$b$|):
\end_layout

\begin_layout Plain Layout

    for iv2 in range(0, |$c_{out}$|):
\end_layout

\begin_layout Plain Layout

      for iv3 in range(0, |$h$|):
\end_layout

\begin_layout Plain Layout

        for iv4 in range(0, |$w$|):
\end_layout

\begin_layout Plain Layout

	  ...
\end_layout

\begin_layout Plain Layout

	  # e.g., iv5, iv6, iv7 = 2, 3, ${
\backslash
setlength{
\backslash
fboxsep}{1pt}
\backslash
colorbox{Salmon}{
\backslash
texttt{4}}}$
\end_layout

\begin_layout Plain Layout

	  _31 = iv3 + iv6 
\end_layout

\begin_layout Plain Layout

	  _41 = iv4 + iv7 
\end_layout

\begin_layout Plain Layout

	  _51 = input[iv1, iv5, _31, _41] 
\end_layout

\begin_layout Plain Layout

	  _61 = weight[iv2, iv5, iv6, iv7] 
\end_layout

\begin_layout Plain Layout

	  _71 = output[iv1, iv2, iv3, iv4] 
\end_layout

\begin_layout Plain Layout

	  _81 = _51 * _61 
\end_layout

\begin_layout Plain Layout

	  |${
\backslash
setlength{ 
\backslash
fboxsep}{1pt} 
\backslash
colorbox{green}{ 
\backslash
texttt{
\backslash
_91}}}$| = _71 + _81 
\end_layout

\begin_layout Plain Layout

	  output[iv1, iv2, iv3, iv4] = _91 
\end_layout

\begin_layout Plain Layout

	  # iv5, iv6, iv7 = 2, 3, ${
\backslash
setlength{
\backslash
fboxsep}{1pt}
\backslash
colorbox{Salmon}{
\backslash
texttt{5}}}$
\end_layout

\begin_layout Plain Layout

	  _32 = iv3 + iv6 
\end_layout

\begin_layout Plain Layout

	  _42 = iv4 + iv7 
\end_layout

\begin_layout Plain Layout

	  _52 = input[iv1, iv5, _32, _42] 
\end_layout

\begin_layout Plain Layout

	  _62 = weight[iv2, iv5, iv6, iv7] 
\end_layout

\begin_layout Plain Layout

	  |${
\backslash
setlength{
\backslash
fboxsep}{1pt}
\backslash
colorbox{yellow}{
\backslash
texttt{
\backslash
_72}}}$| = output[iv1, iv2, iv3, iv4] 
\end_layout

\begin_layout Plain Layout

	  _82 = _52 * _62 
\end_layout

\begin_layout Plain Layout

	  _92 = |${
\backslash
setlength{
\backslash
fboxsep}{1pt}
\backslash
colorbox{yellow}{
\backslash
texttt{
\backslash
_72}}}$| + _82 
\end_layout

\begin_layout Plain Layout

	  output[iv1, iv2, iv3, iv4] = _92
\end_layout

\begin_layout Plain Layout

	  ...
\end_layout

\begin_layout Plain Layout

\begin_inset Caption Standard

\begin_layout Plain Layout
Store-load forwarding across successive iterations (e.g.,
\family typewriter
 iv7
\family default
 
\begin_inset ERT
status open

\begin_layout Plain Layout

$={
\backslash
setlength{
\backslash
fboxsep}{1pt}
\backslash
colorbox{Salmon}{
\backslash
texttt{4}}}, {
\backslash
setlength{
\backslash
fboxsep}{1pt}
\backslash
colorbox{Salmon}{
\backslash
texttt{5}}}$
\end_layout

\end_inset

) of the inner loop in listing 
\begin_inset CommandInset ref
LatexCommand ref
reference "lis:Single-filter-convolution"

\end_inset

, after unrolling.
 The forwarding opportunity is from the store on line 19 to the load on
 line 25; both can be eliminated and 
\begin_inset ERT
status open

\begin_layout Plain Layout

${
\backslash
setlength{
\backslash
fboxsep}{1pt}
\backslash
colorbox{green}{
\backslash
texttt{
\backslash
_91}}}$
\end_layout

\end_inset

 can replace uses of 
\begin_inset ERT
status open

\begin_layout Plain Layout

${
\backslash
setlength{
\backslash
fboxsep}{1pt}
\backslash
colorbox{yellow}{
\backslash
texttt{
\backslash
_72}}}$
\end_layout

\end_inset

, such as in the computation of 
\family typewriter
_92
\family default
 (and potentially many others).
\begin_inset CommandInset label
LatexCommand label
name "lis:Single-filter-convolution-1"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

 In order for this transformation to be correct (preserve program semantics),
 for each pair of candidate store and load operations, it must be verified
 that there are no intervening memory operations.
 Note, the number of such checks scales polynomially in the parameters of
 the convolution since the loop nest unrolls into 
\begin_inset Formula $b\times c_{out}\times h\times w\times c_{in}\times k^{2}$
\end_inset

 store-load pairs.
 Note also, while in the case of listing 
\begin_inset CommandInset ref
LatexCommand ref
reference "lis:Single-filter-convolution"

\end_inset

 the verification is straightforward, in general it might involve solving
 a small constraint satisfaction program 
\begin_inset CommandInset citation
LatexCommand cite
key "rajopadhye2002dependence"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Finally, note, though greedy solutions to the scheduling problem solved
 by HLS are possible, in principle scheduling is an integer linear programming
 problem (ILP), instances of which are NP-hard.
 In summary, HLS tools solve computationally intensive problems in order
 to produce a RTL description of a high-level representation of a DNN.
 These phases of the HLS process incur 
\begin_inset Quotes eld
\end_inset

development time
\begin_inset Quotes erd
\end_inset

 costs (i.e., runtime of the tools) and impose practical limitations on the
 amount of design space exploration (for the purpose of achieving latency
 goals) which can be performed.
 
\family typewriter
BraggHLS 
\family default
addresses these issues by enabling the user to employ heuristics (during
 both the parallelization and scheduling phases) which, while not guaranteed
 to be correct, can be 
\emph on
behaviourally verified
\emph default
 (see section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Symbolic-execution-for"

\end_inset

).
\end_layout

\begin_layout Subsection
FPGA design
\end_layout

\begin_layout Standard
At the register-transfer level of abstraction, there remain two more steps
 prior to being able to actually deploy to an FPGA; one of them being a
 final lowering, so called logic synthesis, and the other being place and
 route (P&R).
 Logic synthesis is the process of mapping RTL to actual hardware primitives
 on the FPGA (so-called 
\emph on
technology mapping
\emph default
), such as lookup tables (LUTs), block RAMs (BRAMs), flip-flops (FFs), and
 digital signal processors (DSPs).
 Logic synthesis produces a network list (
\emph on
netlist
\emph default
) describing the logical connectivity of various parts of the design.
 Logic synthesis effectively determines the implementation of floating point
 operations in terms of DSPs; depending on user parameters and other design
 features, DSP resource consumption for floating point multiplication and
 addition can differ greatly.
 The number of LUTs and DSPs that a high-level representation of a DNN correspon
ds to is relevant to both the performance and feasibility of that DNN when
 deployed to FPGA.
\end_layout

\begin_layout Standard
After the netlist has been produced, the entire design undergoes P&R.
 The goal of P&R is to determine which configurable logic block within an
 FPGA should implement each of the units of logic required by the digital
 design.
 P&R algorithms need to minimize distances between related units of functionalit
y (in order to minimize wire delay), balance wire density across the entire
 fabric of the FPGA (in order to reduce route congestion), and maximize
 the clock speed of the design (a function of both wire delay, logic complexity,
 and route congestion).
 The final, routed design, can then be deployed to the FPGA by producing
 a proprietary 
\emph on
bitstream
\emph default
, which is written to the FPGA.
\end_layout

\begin_layout Section

\family typewriter
BraggHLS
\family default
 compiler and HLS framework
\begin_inset CommandInset label
LatexCommand label
name "sec:BraggHLS-compiler-and"

\end_inset


\end_layout

\begin_layout Standard

\family typewriter
BraggHLS
\family default
 is a customizable HLS framework which employs MLIR for extracting loop-nest
 representations of DNNs implemented as PyTorch models.
 Critically, and distinctly, it handles the DNN transformations as well
 as scheduling, binding, and FSM extraction; there is no dependence on any
 commercial HLS tools.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:BraggHLS-framework-overview."

\end_inset

 shows the architecture of 
\family typewriter
BraggHLS
\family default
 
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../figures/BraggHLS.pdf
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\family typewriter
BraggHLS
\family default
 framework overview (placeholder).
\begin_inset CommandInset label
LatexCommand label
name "fig:BraggHLS-framework-overview."

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

.
 We discuss the most significant aspects of the architecture in the following.
\end_layout

\begin_layout Subsection
Abstract interpretation for efficient transformations
\begin_inset CommandInset label
LatexCommand label
name "subsec:Symbolic-execution-for"

\end_inset


\end_layout

\begin_layout Standard
First, DNNs are lowered from PyTorch to MLIR through TorchScript and the
 
\family typewriter
torch
\family default
 dialect.
 They are then further lowered from the 
\family typewriter
torch
\family default
 dialect to the 
\family typewriter
scf
\family default
 dialect (through the 
\family typewriter
linalg
\family default
 dialect) in such a way that the inherent parallelism of each high-level
 operation is preserved (for example, see listing 
\begin_inset CommandInset ref
LatexCommand ref
reference "lis:Single-filter-convolution-2"

\end_inset

).
 
\begin_inset listings
lstparams "language=MuPAD,float,fontsize={\footnotesize},escapeinside={||},mathescape=true"
inline false
status open

\begin_layout Plain Layout

@conv2d(
\end_layout

\begin_layout Plain Layout

    %input: memref<|$b 
\backslash
times c_{in} 
\backslash
times h 
\backslash
times w$|>,
\end_layout

\begin_layout Plain Layout

    %weight: memref<|$b 
\backslash
times c_{out} 
\backslash
times h 
\backslash
times w$|>,
\end_layout

\begin_layout Plain Layout

    %output: memref<|$c_{out} 
\backslash
times c_{in} 
\backslash
times k 
\backslash
times k$|>
\end_layout

\begin_layout Plain Layout

) {
\end_layout

\begin_layout Plain Layout

  scf.parallel (%iv1, %iv2, %iv3, %iv4) =
\end_layout

\begin_layout Plain Layout

               (%c0, %c0, %c0, %c0) to
\end_layout

\begin_layout Plain Layout

               (|$b$|, |$c_{out}$|, |$h$|, |$w$|) step
\end_layout

\begin_layout Plain Layout

               (%c1, %c1, %c1, %c1) {
\end_layout

\begin_layout Plain Layout

    scf.for %iv5 = %c0 to |$c_{in}$| step %c1 {
\end_layout

\begin_layout Plain Layout

      scf.for %iv6 = %c0 to |$k$| step %c1 {
\end_layout

\begin_layout Plain Layout

        scf.for %iv7 = %c0 to |$k$| step %c1 {
\end_layout

\begin_layout Plain Layout

          %3 = arith.addi %iv3, %iv6
\end_layout

\begin_layout Plain Layout

          %4 = arith.addi %iv4, %iv7
\end_layout

\begin_layout Plain Layout

          %5 = memref.load %input[%iv1, %iv5, %iv3, %3, %4]
\end_layout

\begin_layout Plain Layout

          %6 = memref.load %weight[%iv2, %iv5, %iv6, %iv7]
\end_layout

\begin_layout Plain Layout

          %7 = memref.load %output[%iv1, %iv2, %iv3, %iv4]
\end_layout

\begin_layout Plain Layout

          %8 = arith.mulf %5, %6
\end_layout

\begin_layout Plain Layout

          %9 = arith.addf %7, %8
\end_layout

\begin_layout Plain Layout

          memref.store %9, %output[%iv1, %iv2, %iv3, %iv4]
\end_layout

\begin_layout Plain Layout

        }
\end_layout

\begin_layout Plain Layout

      }
\end_layout

\begin_layout Plain Layout

    }
\end_layout

\begin_layout Plain Layout

  }
\end_layout

\begin_layout Plain Layout

  return %2
\end_layout

\begin_layout Plain Layout

}
\begin_inset Caption Standard

\begin_layout Plain Layout
Parallel loop representation of the convolution in listing 
\begin_inset CommandInset ref
LatexCommand ref
reference "lis:Single-filter-convolution"

\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "lis:Single-filter-convolution-2"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

The value of making the parallelism explicit is that we can readily partition
 a DNN across a known set of hardware resources; since for each value of
 (
\family typewriter
%iv1
\family default
,
\family typewriter
 %iv2
\family default
,
\family typewriter
 %iv3
\family default
,
\family typewriter
 %iv4
\family default
) the body of the 
\family typewriter
scf.parallel
\family default
 is independent of all others we can bind all the respective operations
 to unique hardware resources (DSPs, LUTs, and FFs).
 Thus, we can infer peak resource usage by computing the maximum cardinality
 of the cartesian product of the iteration spaces of the parallel iteration
 variables over all such parallel loops.
 For example, the convolution in listing 
\begin_inset CommandInset ref
LatexCommand ref
reference "lis:Single-filter-convolution-2"

\end_inset

 would bind to 
\begin_inset Formula 
\begin{multline*}
K=\left|\left\{ \texttt{\%iv1}=\texttt{\%c0}+\texttt{\%c1}\times\mathbb{N}\,\wedge\,\texttt{\%iv1}<b\right\} \right|\times\\
\left|\left\{ \texttt{\%iv2}=\texttt{\%c0}+\texttt{\%c1}\times\mathbb{N}\,\wedge\,\texttt{\%iv2}<c_{out}\right\} \right|\times\\
\left|\left\{ \texttt{\%iv3}=\texttt{\%c0}+\texttt{\%c1}\times\mathbb{N}\,\wedge\,\texttt{\%iv3}<h\right\} \right|\times\\
\left|\left\{ \texttt{\%iv4}=\texttt{\%c0}+\texttt{\%c1}\times\mathbb{N}\,\wedge\,\texttt{\%iv4}<w\right\} \right|
\end{multline*}

\end_inset

collections of resources (such as 
\begin_inset Formula $2K$
\end_inset

 DSPs
\begin_inset Foot
status open

\begin_layout Plain Layout
One per floating point operation.
\end_layout

\end_inset

), where 
\begin_inset Formula $\texttt{\%c1}\times\mathbb{N}$
\end_inset

 represents all multiples of 
\begin_inset Formula $\texttt{\%c1}$
\end_inset

.
\end_layout

\begin_layout Standard
In addition to enabling us to perform binding, as discussed in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:High-level-synthesis"

\end_inset

, a loop-nest representation enables us to effectively perform data-flow
 analysis and schedule the encompassed arithmetic operations, given that
 we can first unroll the loops.
 As also discussed in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:High-level-synthesis"

\end_inset

, the formally correct approach to unrolling a loop nest is prohibitively
 expensive in terms of runtime.
 Indeed, for 
\family typewriter
BraggNN
\family default
, with respect to producing a RTL representation achieving latency within
 1000
\begin_inset Formula $\times$
\end_inset

 of the target latency (i.e., 
\begin_inset Formula $<$
\end_inset

1 ms), performing this unrolling in a reasonable amount of time (e.g., 
\begin_inset Formula $<$
\end_inset

12 hours) was extremely challenging.
 
\end_layout

\begin_layout Standard
To overcome this, the approach that 
\family typewriter
BraggHLS
\family default
 takes is to implement an 
\emph on
abstract interpreter
\emph default
 for these loop-nest representations.
 The 
\family typewriter
BraggHLS
\family default
 interpreter unrolls loops by executing under a redefined set semantics
 (hence abstract) them while enforcing SSA.
 That is to say, for a loop whose body has repeated assignments to the same
 value (ostensibly violating SSA), we execute the loop and instantiate unique
 identifiers for the result of each operation.
 The interpreter then evaluates functions of iteration variables, such as
 
\begin_inset listings
lstparams "language=MuPAD"
inline true
status open

\begin_layout Plain Layout

%3 = arith.addi %iv3, %iv6
\end_layout

\end_inset

.
 This enables us to determine array index operands of all stores and loads,
 such as 
\begin_inset listings
lstparams "language=MuPAD"
inline true
status open

\begin_layout Plain Layout

memref.load %input[%iv1, %iv5, %iv3, %3, %4]
\end_layout

\end_inset

.
 Note, we do not evaluate values corresponding to floating point arithmetic,
 as they represent true evaluation of the DNN; our interpreter represents
 the operands of such operations as symbols and merely records the arithmetic
 operations performed on them.
 This enables us to both unroll the loop and track data-flow through arithmetic
 operations (see section 
\begin_inset CommandInset ref
LatexCommand ref
reference "lis:Single-filter-convolution-1"

\end_inset

).
 Finally, the interpreter reinterprets 
\family typewriter
memref
\family default
s as 
\emph on
geometric symbol tables
\emph default
 (i.e., symbol tables indexed by array indices rather than identifiers/names)
 and stores and loads as assignments/reads to/from those symbol tables.
 Such semantics, in combination with fully evaluated array indices, enables
 
\family typewriter
BraggHLS
\family default
 to simultaneously track the flow of data (through arithmetic operations
 and 
\family typewriter
memref
\family default
s), effectively performing store-load forwarding.
\end_layout

\begin_layout Section
Evaluation
\begin_inset CommandInset label
LatexCommand label
name "sec:Evaluation"

\end_inset


\end_layout

\begin_layout Standard
asdasd
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../data/addmm.pdf
	lyxscale 50
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\family typewriter
addmm
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "2dlattice-1-1-2"

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../data/braggnn.pdf
	lyxscale 50
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\family typewriter
braggnn
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "2dlattice-1-2-2"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset CommandInset label
LatexCommand label
name "2dlattice-1-3"

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../data/conv.pdf
	lyxscale 50
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\family typewriter
conv
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "2dlattice-1-1-1-1"

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../data/matmul.pdf
	lyxscale 50
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\family typewriter
matmul
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "2dlattice-1-2-1-1"

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Resource usage and latency vs.
 unroll factor of various DNN modules.
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../data/elapsed_time.pdf
	lyxscale 50
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Runtime of Vitis HLS vs.
 unroll factor.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section

\family typewriter
BraggNN
\family default
 case study
\begin_inset CommandInset label
LatexCommand label
name "sec:BraggNN-case-study"

\end_inset


\end_layout

\begin_layout Section
Conclusion
\begin_inset CommandInset label
LatexCommand label
name "sec:Conclusion"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Remember though that your final submission is supposed to have all the bibliogra
phy entries embedded in the \SpecialChar LaTeX
-file.
 This means you eventually have to copy the .bbl file into the latex file
 and remove the bibtex lines.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "ref"
options "IEEEtran"

\end_inset


\end_layout

\end_body
\end_document
